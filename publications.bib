@inproceedings{karim2020classification,
title={{Classification Benchmarks for Under-resourced Bengali Language based on Multichannel Convolutional-LSTM Network}},
author="Md. Rezaul Karim and Bharathi Raja Chakravarthi and John P. McCrae and Michael Cochez",
affiliation="['', 'NUIG', 'NUIG', '']",
year="2020 (Accepted)",
booktitle="IEEE DSAA 2020 The 7th IEEE International Conference on Data Science and Advanced Analytics",
description="Exponential growths of social media and micro-blogging sites not only provide platforms for empowering freedom of expressions and individual voices, but also enables people to express anti-social behaviour like online harassment, cyberbullying, and hate speech. Numerous works have been proposed to utilize these data for social and anti-social behaviours analysis, document characterization, and sentiment analysis by predicting the contexts mostly for highly resourced languages like English.  However, some languages are under-resources, e.g., South Asian languages like Bengali, Tamil, Assamese, Malayalam that lack of computational resources for natural language processing. In this paper, we provide several classification benchmarks for Bengali, an under-resourced language. We prepared three datasets of expressing hate, commonly used topics, and opinions for hate speech detection, document classification, and sentiment analysis.  We built the largest Bengali word embedding models to date based on 250 million articles, which we call BengFastText.  We perform three experiments, covering document classification, sentiment analysis, and hate speech detection. We incorporate word embeddings into a Multichannel Convolutional-LSTM (MC-LSTM) network for predicting different types of hate speech, document classification, and sentiment analysis. Experiments demonstrate that BengFastText can capture the semantics of words from respective contexts correctly. Evaluations against several baseline embedding models, e.g., Word2Vec and GloVe yield up to 92.30\%, 82.25\%, and 90.45\% F1-scores in case of document classification, sentiment analysis, and hate speech detection, respectively during 5-fold cross-validation tests"
}

@inproceedings{chakravarthi2020overview,
title={{Overview of the track on Sentiment Analysis for DravidianLanguages in Code-Mixed Text}},
author="Bharathi Raja Chakravarth and Ruba Priyadharshini and Vigneshwaran Muralidaran and Shardul Suryawanshi and Navya Jose and Elizabeth Sherly and John P. McCrae",
affiliation="['NUIG', 'ULTRA Arts and Science College', 'Cardiff University', 'NUIG', 'Indian Institute of Information Technology and Management-Kerala', 'Indian Institute of Information Technology and Management-Kerala', 'NUIG']",
year="2020 (Accepted)",
booktitle="Proceedings of Hate Speech and Offensive Content Identification in Indo-European Languages (HASOC 2020)",
description="Sentiment analysis of Dravidian languages has received attention in recent years. However, most social media text is code-mixed and there is no research available on sentiment analysis of code-mixed Dravidian languages.  The Dravidian-CodeMix-FIRE 2020, a track on Sentiment Analysis for Dravidian Languages in Code-Mixed Text, focused on creating a platform for researchers to come together and investigate the problem.  There were two languages for this track: (i) Tamil, and (ii) Malayalam. The participants were given a dataset of YouTube comments and the goal of the shared task submissions was to recognise the sentiment of each comment by classifying them into positive, negative, neutral, mixed-feeling classes or by recognising whether the comment is not in the intended language. The performance of the systems was evaluated by weighted-F1 score."
}

@inproceedings{ojha2020nuig,
title={{NUIG-Panlingua-KMI Hindi\ensuremath{\leftrightarrow}Marathi MT Systems for SimilarLanguage Translation Task @ WMT 2020}},
author="Atul Kr. Ojha and Priya Rani and Akanksha Bansal and Bharathi Raja Chakravarthi and Ritesh Kumar and John P. McCrae",
year="2020 (Accepted)",
booktitle="Proceedings of the Fifth Conference on Machine Translation (WMT20)",
affiliation="['NUIG', 'NUIG', 'Panlingua Language Processing LLP', 'NUIG', 'Dr. Bhimrao Ambedkar University', 'NUIG']",
description="NUIG-Panlingua-KMI submission to WMT 2020 seeks to push the state-of-the-art in Similar Language Translation Task for Hindi \ensuremath{<}-\ensuremath{>} Marathi language pair. As part of these efforts, we conducted a series of experiments to address the challenges for translation between similar languages. Among the 4 MT systems prepared under this task, 1 PBSMT systems were prepared for  Hindi \ensuremath{<}-\ensuremath{>} Marathi each and 1 NMT systems were developed for Hindi \ensuremath{<}-\ensuremath{>} Marathi using Byte Pair En-coding (BPE) into subwords. The results show that different architectures in NMT could be an effective method for developing MT systems for closely related languages. Our Hindi-Marathi NMT system was ranked 8th among the 14 teams that participated and our Marathi-Hindi NMT system was ranked 8th among the 11 teams participated for the task."
}

@inproceedings{zayed2020contextual,
title={{Contextual Modulation for Relation-Level Metaphor Identification}},
author="Omnia Zayed and John P. McCrae and Paul Buitelaar",
year="2020 (Accepted)",
booktitle="EMNLP Frontiers",
affiliation="['NUIG', 'NUIG', 'NUIG']",
description="Identifying metaphors in text is very challenging and requires comprehending the underlying comparison. The automation of this cognitive process has gained wide attention lately. However, the majority of existing approaches concentrate on word-level identification by treating the task as either single-word classification or sequential labelling without explicitly modelling the interaction between the metaphor components. On the other hand, while existing relation-level approaches implicitly model this interaction, they ignore the context where the metaphor occurs. In this work, we address these limitations by introducing a novel architecture for identifying relation-level metaphoric expressions of certain grammatical relations based on contextual modulation. In a methodology inspired by works in visual reasoning, our approach is based on conditioning the neural network computation on the deep contextualised features of the candidate expressions using feature-wise linear modulation. We demonstrate that the proposed architecture achieves state-of-the-art results on benchmark datasets. The proposed methodology is generic and could be applied to other textual classification problems that benefit from contextual interaction."
}

@inproceedings{goswami2020unsupervised,
title={{Unsupervised Deep Language and Dialect Identification for Short Texts}},
author="Koustava Goswami and Rajdeep Sarkar and Bharathi Raja Chakravarthi and Theodorus Fransen and John P. McCrae",
year="2020 (Accepted)",
booktitle="Proceedings of the 28th International Conference on Computational Linguistics (COLING'2020)",
affiliation="['NUIG', 'NUIG', 'NUIG', 'NUIG', 'NUIG']",
description="Automatic Language Identification (LI) or Dialect Identification (DI) of short texts of closely related languages or dialects, is one of the primary steps in many natural language processing pipelines.  Language identification is considered a solved task in many cases; however, in the case of very closely related languages, or in an unsupervised scenario (where the languages are not known in advance), performance is still poor.  In this paper, we propose the Unsupervised Deep Language and Dialect Identification (UDLDI) method, which can simultaneously learn sentence embeddings and cluster assignments from short texts.  The UDLDI model understands the sentence constructions of languages by applying attention to character relations which helps to optimize the clustering of languages.  We have performed our experiments on three short-text datasets for different language families, each consisting of closely related languages or dialects, with very minimal training sets. Our experimental evaluations on these datasets have shown significant improvement over state-of-the-art unsupervised methods and our model has outperformed state-of-the-art LI and DI systems in supervised settings."
}

@inproceedings{sarkar2020suggest,
title={{{\textquotedblleft}Suggest me a movie for tonight{\textquotedblright}: Leveraging Knowledge Graphs forConversational Recommendation}},
author="Rajdeep Sarkar and Koustava Goswami and Mihael Arcan and John P. McCrae",
year="2020 (Accepted)",
booktitle="Proceedings of the 28th International Conference on Computational Linguistics (COLING'2020)",
affiliation="['NUIG', 'NUIG', 'NUIG', 'NUIG']",
description="Conversational recommender systems focus on the task of suggesting products to users based on the conversation flow. Recently, the use of external knowledge in the form of knowledge graphs has shown to improve the performance in recommendation and dialogue systems. Information from knowledge graphs aids in enriching those systems by providing additional information such as closely related products and textual descriptions of the items. However, knowledge graphs are incomplete since they do not contain all factual information present on the web. Also, when working on a specific domain, knowledge graphs in its entirety contribute towards extraneous information and noise. In this work, we study several subgraph construction methods and compare their performance across the recommendation task. We incorporate pre-trained embeddings from the subgraphs along with positional embeddings in our models. Extensive experiments show that our method has a relative improvement of at least 5.62\% compared to the state-of-the-art on multiple metrics on the recommendation task."
}

@inproceedings{chakravarthi2020bilingual,
title={{Bilingual Lexicon Induction across Orthographically-distinctUnder-Resourced Dravidian Languages}},
author="Bharathi Raja Chakravarthi and Navaneethan Rajasekaran and Mihael Arcan and Kevin McGuinness and Noel E. O{\textquoteright}Connor and John P. McCrae",
affiliation="['NUIG', 'Dublin City University', 'NUIG', 'Dublin City University', 'Dublin City University', 'NUIG']",
year="2020 (Accepted)",
booktitle="Proceedings of the Seventh Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial 2020)",
description="Bilingual lexicons are a vital tool for under-resourced languages and recent state-of-the-art approaches to this leverage pretrained monolingual word embeddings using supervised or semi-supervised approaches. However, these approaches require cross-lingual information such as seed dictionaries to train the model and find a linear transformation between the word embedding spaces. Especially in the case of low-resourced languages, seed dictionaries are not readily available, and as such, these methods produce extremely weak results on these languages. In this work, we focus on the Dravidian languages, namely Tamil, Telugu, Kannada, and Malayalam, which are even more challenging as they are written in unique scripts.  To take advantage of orthographic information and cognates in these languages, we bring the related languages into a single script. Previous approaches have used linguistically sub-optimal measures such as the Levenshtein edit distance to detect cognates, whereby we demonstrate that the longest common sub-sequence is linguistically more sound and improves the performance of bilingual lexicon induction. We show that our approach can increase the accuracy of bilingual lexicon induction methods on these languages many times, making bilingual lexicon induction approaches feasible for such under-resourced languages."
}

@inproceedings{nasir2020ilod,
title={{iLOD: InterPlanetary File System based Linked Open Data Cloud}},
author="Jamal A. Nasir and John P. McCrae",
affiliation="['NUIG', 'NUIG']",
year="2020 (Accepted)",
booktitle="Proceedings of MEPDaW'20 - Managing the Evolution and Preservation of the Data Web at ISWC 2020",
description="The proliferation of the World Wide Web and the Semantic Web applications has led to an increase in distributed services and datasets. This increase has put the infrastructural load in terms of availability, immutability, and security, and these challenges are being failed by the Linked Open Data (LOD) cloud due to the brittleness of its decentralisation. In this work, we present iLOD: a peer-to-peer decentralized storage infrastructure using the InterPlanetary File System (IPFS). iLOD is a dataset sharing system that leverages content-based addressing to support a resilient internet, and can speed up the web by getting nearby copies. In this study, we empirically analyze and evaluate the availability limitations of LOD and propose a distributed system for storing and accessing linked datasets without requiring any centralized server."
}

@inproceedings{declerck2020cost,
title={{COST Action {\textquotedblleft}European network for Web-centred linguistic data science{\textquotedblright} (NexusLinguarum)}},
author="Thierry Declerck and Jorge Gracia and John P. McCrae",
affiliation="['DFKI GmbH', 'University of Zaragoza', 'NUIG']",
year="2020",
booktitle="Procesamiento del Lenguaje Natural",
number="65",
pages="93-96",
description="We present the current state of the large {\textquotedblleft}European network for Web-centred linguistic data science{\textquotedblright}. In its first phase, the network has put in place several working groups to deal with specific topics. The network also already implemented a first round of Short Term Scientific Missions (STSM)",
url="http://journal.sepln.org/sepln/ojs/ojs/index.php/pln/article/view/6281/3717",
doi="10.26342/2020-65-11"
}

@article{mccrae2020english2,
title={{English WordNet: A new open-source WordNet for English}},
author="John P. McCrae and Ewa Rudnicka and Francis Bond",
year="2020",
journal="K Lexical News",
number="28",
pages="37-44",
affiliation="['NUIG', 'Wroclaw University of Science and Technology', 'Nanyang Technological University']"
}

@book{cimiano2020linguistic,
title={{Linguistic Linked Data: Representation, Generation and Applications}},
author="Philipp Cimiano and Christian Chiarcos and John P. McCrae and Jorge Gracia",
year="2020",
isbn="978-3-030-30225-2",
publisher="Springer",
url="https://www.springer.com/gp/book/9783030302245"
}

@proceedings{ionov2020linked,
title={{7th Workshop on Linked Data in Linguistics (LDL-2020)}},
editor="Maxim Ionov and John P. McCrae and Christian Chiarcos and Thierry Declerck and Julia Bosque-Gil and Jorge Gracia",
year="2020",
isbn="979-10-95546-36-8",
publisher="European Language Resources Association (ELRA)",
address="9 rue des Cordeli\`eres, 75013, Paris, France",
series="LREC 2020 Workshop Language Resources and Evaluation Conference",
url="https://lrec2020.lrec-conf.org/media/proceedings/Workshops/Books/LDL2020book.pdf",
date="2020-05-11"
}

@proceedings{kernerman2020globalex,
title={{Globalex Workshop on Linked Lexicography}},
editor="Ilan Kernerman and Simon Krek and John P. McCrae and Jorge Gracia and Sina Ahmadi and Besim Kabashi",
year="2020",
isbn="979-10-95546-46-7",
publisher="European Language Resources Association (ELRA)",
address="9 rue des Cordeli\`eres, 75013, Paris, France",
series="LREC 2020 Workshop Language Resources and Evaluation Conference",
url="https://lrec2020.lrec-conf.org/media/proceedings/Workshops/Books/GLOBALEX2020book.pdf",
date="2020-05-11"
}

@inproceedings{jose2020survey,
title={{A Survey of Current Datasets for Code-Switching Research}},
author="Navya Jose and Bharathi Raja Chakravarthi and Shardul Suryawanshi and Elizabeth Sherly and John P.McCrae",
year="2020",
booktitle="ICACCS 2020: International Conference on Advanced Computing \& Communication Systems (ICACCS)",
date="2020-03-06",
affiliation="['Indian Institute of Information Technology and Management-Kerala', 'NUIG', 'NUIG', 'Indian Institute of Information Technology and Management-Kerala', 'NUIG']",
url="https://ieeexplore.ieee.org/abstract/document/9074205",
pages="136-141",
doi="10.1109/ICACCS48705.2020.9074205",
description="Code switching is a prevalent phenomenon in the multilingual community and social media interaction. In the past ten years, we have witnessed an explosion of code switched data in the social media that brings together languages from low resourced languages to high resourced languages in the same text, sometimes written in a non-native script. This increases the demand for processing code-switched data to assist users in various natural language processing tasks such as part-of-speech tagging, named entity recognition, sentiment analysis, conversational systems, and machine translation, etc. The available corpora for code switching research played a major role in advancing this area of research. In this paper, we propose a set of quality metrics to evaluate the dataset and categorize them accordingly."
}

@inproceedings{priyadharshini2020named,
author="Ruba Priyadharshini, Bharathi Raja Chakravarthi, Mani Vegupatti and John P.Mccrae",
title={{Named Entity Recognition for Code-Mixed Indian Corpus using Meta Embedding}},
booktitle="ICACCS 2020: International Conference on Advanced Computing \& Communication Systems (ICACCS)",
date="2020-03-06",
year="2020",
affiliation="['Saraswathi Narayanan College,Department of Mathematics', 'NUIG', 'NUIG', 'NUIG']",
url="https://ieeexplore.ieee.org/abstract/document/9074379",
pages="68-72",
doi="10.1109/ICACCS48705.2020.9074379",
description="In this paper, we utilize the pre-trained embedding, sub-word embedding and closely related languages of languages in the code mixed corpus to create a meta-embedding. We then use the Transformer to encode the code mixed sentence and use Conditional Random Field to predict the Named Entities in the code-mixed text. In contrast to classical Named Entity recognition where the text is monolingual, our approach can predict the Named Entities in code-mixed corpus written both in the native script as well as Roman script. Our method is a novel method to combine the embeddings of closely related languages to identify Named Entity from Code-Mixed Indian text written using native script and Roman script in social media."
}

@inproceedings{declerck2020linguistic,
title={{On the Linguistic Linked Open Data Infrastructure}},
author="Christian Chiarcos and Bettina Klimek and Christian F\"ath and Thierry Declerck and John P. McCrae",
affiliation="['Goethe-Universit\"at Frankfurt am Main', 'Universit\"at Leipzig', 'Goethe-Universit\"at Frankfurt am Main', 'DFKI GmbH', 'NUIG']",
date="2020-05-11",
booktitle="Proceedings of the 1st International Workshop on Language Technology Platforms at LREC 2020",
year="2020",
url="https://lrec2020.lrec-conf.org/media/proceedings/Workshops/Books/IWLTP2020book.pdf\#page=14",
pages="8-15",
description="In this paper we describe the current state of development of the Linguistic Linked Open Data (LLOD) infrastructure, an LOD (sub-)cloud of linguistic resources, which covers various linguistic data bases, lexicons, corpora, terminology and metadata repositories.  We give in some details an overview of the contributions made by the European H2020 projects {\textquotedblleft}Pr\^et-\`a-LLOD{\textquotedblright} ({\textquoteleft}Ready-to-use Multilingual Linked Language Data for Knowledge Services across Sectors{\textquoteright}) and {\textquotedblleft}ELEXIS{\textquotedblright} ({\textquoteleft}European Lexicographic Infrastructure{\textquoteright}) to the further development of the LLOD"
}

@inproceedings{mccrae2020nuig,
title={{NUIG at TIAD: Combining Unsupervised NLP and Graph Metrics for Translation Inference}},
author="John P. McCrae and Mihael Arcan",
affiliation="['NUIG', 'NUIG']",
date="2020-05-11",
booktitle="Proceedings of the Globalex Workshop on Linked Lexicography (@LREC 2020)",
year="2020",
url="https://lrec2020.lrec-conf.org/media/proceedings/Workshops/Books/GLOBALEX2020book.pdf\#page=110",
pages="92-97",
description="In this paper, we present the NUIG system at the TIAD shared task. This system includes graph-based metrics calculated using novel algorithms, with an unsupervised document embedding tool called ONETA and an unsupervised multi-way neural machine translation method. The results are an improvement over our previous system and produce the highest precision among all systems in the task as well as very competitive F-Measure results. Incorporating features from other systems should be easy in the framework we describe in this paper, suggesting this could very easily be extended to an even stronger result."
}

@inproceedings{rani2020comparative,
title={{A Comparative Study of Different State-of-the-Art Hate Speech Detection Methods in Hindi-English Code-Mixed Data}},
author="Priya Rani and Shardul Suryawanshi and Koustava Goswami and Bharathi Raja Chakravarthi and Theodorus Fransen and John Philip McCrae",
affiliation="['NUIG', 'NUIG', 'NUIG', 'NUIG', 'NUIG', 'NUIG']",
date="2020-05-11",
booktitle="Proceedings of the Second Workshop on Trolling, Aggression and Cyberbullying at LREC 2020",
year="2020",
url="https://lrec2020.lrec-conf.org/media/proceedings/Workshops/Books/TRAC2book.pdf\#page=55",
pages="42-48",
description="Hate speech detection in social media communication has become one of the primary concerns to avoid conflicts and curb undesired activities. In an environment where multilingual speakers switch among multiple languages, hate speech detection becomes a challenging task using methods that are designed for monolingual corpora. In our work, we attempt to analyze, detect and provide a comparative study of hate speech in a code-mixed social media text. We also provide a Hindi-English code-mixed data set consisting of Facebook and Twitter posts and comments. Our experiments show that deep learning models trained on this code-mixed corpus perform better."
}

@inproceedings{rehm2020towards,
title={{Towards an Interoperable Ecosystem of AI and LT Platforms: A Roadmap for the Implementation of Different Levels of Interoperability}},
author="Georg Rehm and Dimitris Galanis and Penny Labropoulou and Stelios Piperidis and Martin Wel{\ss} and Ricardo Usbeck and Joachim K\"ohler and Miltos Deligiannis and Katerina Gkirtzou and Johannes Fischer and Christian Chiarcos and Nils Feldhus and Julian Moreno-Schneider and Florian Kintzel and Elena Montiel-Ponsoda and V{\'\i}ctor Rodriguez-Doncel and John Philip McCrae and David Laqua and Irina Patricia Theile and Christian Dittmar and Kalina Bontcheva and Ian Roberts and Andrejs Vasi\c{l}jevs and Andis Lagzdins",
affiliation="['DFKI GmbH', 'ILSP/Athena RC', 'ILSP/Athena RC', 'ILSP/Athena RC', 'Fraunhofer IAIS', 'Fraunhofer IAIS', 'Fraunhofer IAIS', 'ILSP/Athena RC', 'ILSP/Athena RC', 'Fraunhofer IIS', 'Goethe University Frankfurt', 'DFKI GmbH', 'DFKI GmbH', 'DFKI GmbH', 'Universidad Polit\'ecnica de Madrid', 'Universidad Polit\'ecnica de Madrid', 'NUIG', 'Fraunhofer IAIS', 'Fraunhofer IAIS', 'Fraunhofer IIS', 'University of Sheffield', 'University of Sheffield', 'Tilde', 'Tilde']",
date="2020-05-11",
booktitle="Proceedings of the 1st International Workshop on Language Technology Platforms at LREC 2020",
year="2020",
url="https://lrec2020.lrec-conf.org/media/proceedings/Workshops/Books/IWLTP2020book.pdf\#page=102",
pages="96-107",
description="With regard to the wider area of AI/LT platform interoperability, we concentrate on two core aspects: (1) cross-platform search and discovery of resources and services; (2) composition of cross-platform service workflows. We devise five different levels (of increasing complexity) of platform interoperability that we suggest to implement in a wider federation of AI/LT platforms. We illustrate the approach using the five emerging AI/LT platforms AI4EU, ELG, Lynx, QURATOR and SPEAKER."
}

@inproceedings{suryawanshi2020dataset,
title={{A Dataset for Classification of Tamil Memes}},
author="Shardul Suryawanshi and Bharathi Raja Chakravarthi and Pranav Verma and Mihael Arcan and John Philip McCrae  and Paul Buitelaar",
affiliation="['NUIG', 'NUIG', 'NUIG', 'NUIG', 'NUIG', 'NUIG']",
date="2020-05-11",
booktitle="Proceedings of the 5th Workshop on Indian Language Data: Resources and Evaluation (WILDRE-5) at LREC-2020",
year="2020",
url="https://lrec2020.lrec-conf.org/media/proceedings/Workshops/Books/WILDRE-5book.pdf\#page=17",
pages="7-13",
description="Social media are interactive platforms that facilitate the creation or sharing of information, ideas or other forms of expression among people. This exchange is not free from offensive, trolling or malicious contents targeting users or communities. One way of trolling is by making memes, which in most cases combines an image with a concept or catchphrase. The challenge of dealing with memes is that they are region-specific and their meaning is often obscured in humour or sarcasm. To facilitate the computational modelling of trolling in the memes for Indian languages, we created a meme dataset for Tamil (TamilMemes). We annotated and released the dataset containing suspected trolls and not-troll memes. In this paper, we use the a image classification to address the difficulties involved in the classification of troll memes with the existing methods. We found that the identification of a troll meme with such an image classifier is not feasible which has been corroborated with precision, recall and F1-score"
}

@inproceedings{chiarcos2020modelling,
title={{Modelling Frequency and Attestations for OntoLex-Lemon}},
author="Christian Chiarcos and Maxim Ionov and Jesse de Does and Katrien Depuydt and Anas Fahad Khan and Sander Stolk and Thierry Declerck and John Philip McCrae",
affiliation="['Goethe-Universit\"at Frankfurt am Main', 'Goethe-Universit\"at Frankfurt am Main', 'Instituut voor de Nederlandse Taal', 'Instituut voor de Nederlandse Taal', 'Istituto di Linguistica Computazionale {\textquotedblleft}A. Zampolli{\textquotedblright} (ILC-CNR) Pisa', 'Leiden University', 'DFKI GmbH', 'NUIG']",
date="2020-05-11",
booktitle="Proceedings of the Globalex Workshop on Linked Lexicography (@LREC 2020)",
year="2020",
url="https://lrec2020.lrec-conf.org/media/proceedings/Workshops/Books/GLOBALEX2020book.pdf\#page=19",
pages="1-9",
description="The OntoLex vocabulary enjoys increasing popularity as a means of publishing lexical resources with RDF and as Linked Data. The recent publication of a new OntoLex module for lexicography, lexicog, reflects its increasing importance for digital lexicography.  However, not all aspects of digital lexicography have been covered to the same extent. In particular, supplementary information drawn from corpora such as frequency information, links to attestations, and collocation data were considered to be beyond the scope of lexicog. Therefore, the OntoLex community has put forward the proposal for a novel module for frequency, attestation and corpus information (FrAC), that not only covers the requirements of digital lexicography, but also accommodates essential data structures for lexical information in natural language processing. This paper introduces the current state of the OntoLex-FrAC vocabulary, describes its structure, some selected use cases, elementary concepts and fundamental definitions, with a focus on frequency and attestations."
}

@inproceedings{salgado2020challenges,
title={{Challenges of Word Sense Alignment: Portuguese Language Resources}},
author="Ana Salgado and Sina Ahmadi and Alberto Sim\~oes and John Philip McCrae and Rute Costa",
affiliation="['Academia das Ciencias de Lisboa, Instituto de Lexicologia e Lexicografia da L{\'\i}ngua Portuguesa', 'NUIG', '2Ai {\textendash} School of Technology', 'NUIG', 'NOVA CLUNL, Universidade NOVA de Lisboa']",
date="2020-05-11",
booktitle="Proceedings of the 7th Workshop on Linked Data in Linguistics: Building tools and infrastructure at LREC 2020",
year="2020",
url="https://lrec2020.lrec-conf.org/media/proceedings/Workshops/Books/LDL2020book.pdf\#page=52",
pages="45-51",
description="This paper reports on an ongoing task of monolingual word sense alignment in which a comparative study between the Portuguese Academy of Sciences Dictionary and the Dicionario Aberto {\textasciiacute} is carried out in the context of the ELEXIS (European Lexicographic Infrastructure) project. Word sense alignment involves searching for matching senses within dictionary entries of different lexical resources and linking them, which poses significant challenges. The lexicographic criteria are not always entirely consistent within individual dictionaries and even less so across different projects where different options may have been assumed in terms of structure and especially wording techniques of lexicographic glosses. This hinders the task of matching senses. We aim to present our annotation workflow in Portuguese using the Semantic Web standards. The results obtained are useful for the discussion within the community"
}

@inproceedings{mccrae2020english,
title={{English WordNet 2020: Improving and Extending a WordNet for English using an Open-Source Methodology}},
author="John Philip McCrae and Alexandre Rademaker and Ewa Rudnicka and Francis Bond",
affiliation="['NUIG', 'IBM Research and FGV/EMAp', 'Wroclaw University of Science and Technology', 'Nanyang Technological University']",
date="2020-05-11",
booktitle="Proceedings of the Multimodal Wordnets Workshop at LREC 2020",
year="2020",
url="https://lrec2020.lrec-conf.org/media/proceedings/Workshops/Books/MMW2020book.pdf\#page=20",
pages="14-19",
description="The Princeton WordNet, while one of the most widely used resources for NLP, has not been updated for a long time, and as such a new project English WordNet has arisen to continue the development of the model under an open-source paradigm. In this paper, we detail the second release of this resource entitled {\textquotedblleft}English WordNet 2020{\textquotedblright}. The work has focused firstly, on the introduction of new synsets and senses and developing guidelines for this and secondly, on the integration of contributions from other projects. We present the changes in this edition, which total over 15,000 changes over the previous release"
}

@inproceedings{chakravarthi2020sentiment,
title={{A Sentiment Analysis Dataset for Code-Mixed Malayalam-English}},
author="Bharathi Raja Chakravarthi and Navya Jose and Shardul Suryawanshi and Elizabeth Sherly and John Philip McCrae",
affiliation="['NUIG', 'Indian Institute of Information Technology and Management-Kerala', 'NUIG', 'Indian Institute of Information Technology and Management-Kerala', 'NUIG']",
date="2020-05-11",
booktitle="Proceedings of 1st Joint SLTU (Spoken Language Technologies for Under-resourced languages) and CCURL (Collaboration and Computing for Under-Resourced Languages) Workshop at LREC 2020",
year="2020",
url="https://lrec2020.lrec-conf.org/media/proceedings/Workshops/Books/SLTUCCURLbook.pdf\#page=186",
pages="177-184",
description="There is an increasing demand for sentiment analysis of text from social media which are mostly code-mixed. Systems trained on monolingual data fail for code-mixed data due to the complexity of mixing at different levels of the text. However, very few resources are available for code-mixed data to create models specific for this data. Although much research in multilingual and cross-lingual sentiment analysis has used semi-supervised or unsupervised methods, supervised methods still performs better. Only a few datasets for popular languages such as English-Spanish, English-Hindi, and English-Chinese are available. There are no resources available for Malayalam-English code-mixed data. This paper presents a new gold standard corpus for sentiment analysis of code-mixed text in Malayalam-English annotated by voluntary annotators. This gold standard corpus obtained a Krippendorff{\textquoteright}s alpha above 0.8 for the dataset. We use this new corpus to provide the benchmark for sentiment analysis in Malayalam-English code-mixed texts."
}

@inproceedings{chakravarthi2020corpus,
title={{Corpus Creation for Sentiment Analysis in Code-Mixed Tamil-English Text}},
author="Bharathi Raja Chakravarthi and Vigneshwaran Muralidaran and Ruba Priyadharshini and John Philip McCrae",
affiliation="['NUIG', 'School of English, Communication and Philosophy, Cardiff University', 'Saraswathi Narayanan College', 'NUIG']",
date="2020-05-11",
booktitle="Proceedings of 1st Joint SLTU (Spoken Language Technologies for Under-resourced languages) and CCURL (Collaboration and Computing for Under-Resourced Languages) Workshop at LREC 2020",
year="2020",
url="https://lrec2020.lrec-conf.org/media/proceedings/Workshops/Books/SLTUCCURLbook.pdf\#page=211",
pages="202-210",
description="Understanding the sentiment of a comment from a video or an image is an essential task in many applications. Sentiment analysis of a text can be useful for various decision-making processes. One such application is to analyse the popular sentiments of videos on social media based on viewer comments. However, comments from social media do not follow strict rules of grammar, and they contain mixing of more than one language, often written in non-native scripts. Non-availability of annotated code-mixed data for a low-resourced language like Tamil also adds difficulty to this problem. To overcome this, we created a gold standard Tamil-English code-switched, sentiment-annotated corpus containing 15,744 comment posts from YouTube. In this paper, we describe the process of creating the corpus and assigning polarities. We present inter-annotator agreement and show the results of sentiment analysis trained on this corpus as a benchmark."
}

@inproceedings{ahmadi2020towards,
title={{Towards Automatic Linking of Lexicographic Data: the case of a historical and a modern Danish dictionary}},
author="Sina Ahmadi and Sanni Nimb and Thomas Troelsg\r{a}rd and John P. McCrae and Nicolai H. S{\o}rensen",
affiliation="['NUIG', 'Society for Danish Language and Literature', 'Society for Danish Language and Literature', 'NUIG', 'Society for Danish Language and Literature']",
date="2020-09-08",
booktitle="Proceedings of the XIX EURALEX International Congress",
year="2020 (Accepted)"
}

@inproceedings{zayed2020figure,
title={{Figure Me Out: A Gold Standard Dataset for Metaphor Interpretation}},
author="Omnia Zayed and John P. McCrae and Paul Buitelaar",
affiliation="['NUIG', 'NUIG', 'NUIG']",
date="2020-05-11",
booktitle="Proceedings of the 12th Language Resource and Evaluation Conference (LREC 2020)",
year="2020",
url="http://www.lrec-conf.org/proceedings/lrec2020/pdf/2020.lrec-1.712.pdf",
pages="5810-5819",
description="Metaphor comprehension and understanding is a complex cognitive task that requires interpreting metaphors by grasping the interaction between the meaning of their target and source concepts. This is very challenging for humans, let alone computers. Thus, automatic metaphor interpretation is understudied in part due to the lack of publicly available datasets. The creation and manual annotation of such datasets is a demanding task which requires huge cognitive effort and time. Moreover, there will always be a question of accuracy and consistency of the annotated data due to the subjective nature of the problem. This work addresses these issues by presenting an annotation scheme to interpret verb-noun metaphoric expressions in text. The proposed approach is designed with the goal of reducing the workload on annotators and maintain consistency. Our methodology employs an automatic retrieval approach which utilises external lexical resources, word embeddings and semantic similarity to generate possible interpretations of identified metaphors in order to enable quick and accurate annotation. We validate our proposed approach by annotating around 1,500 metaphors in tweets which were annotated by six native English speakers. As a result of this work, we publish as linked data the first gold standard dataset for metaphor interpretation which will facilitate research in this area."
}

@inproceedings{bond2020issues,
title={{Some Issues with Building a Multilingual Wordnet}},
author="Francis Bond and Luis Morgado da Costa and Michael Wayne Goodman and John P. McCrae and Ahti Lohk",
affiliation="['Nanyang Technological University', 'Nanyang Technological University', 'Nanyang Technological University', 'NUIG', 'Tallinn University of Technology']",
date="2020-05-11",
booktitle="Proceedings of the 12th Language Resource and Evaluation Conference (LREC 2020)",
year="2020",
url="http://www.lrec-conf.org/proceedings/lrec2020/pdf/2020.lrec-1.390.pdf",
pages="3189-3197",
description="In this paper we discuss the experience of bringing together over 40 different wordnets. We introduce some extensions to the GWA wordnet LMF format proposed in Vossen et al. (2016) and look at how this new information can be displayed. Notable extensions include: confidence, corpus frequency, orthographic variants, lexicalized and non-lexicalized synsets and lemmas, new parts of speech, and more. Many of these extensions already exist in multiple wordnets {\textendash} the challenge was to find a compatible representation. To this end, we introduce a new version of the Open Multilingual Wordnet (Bond and Foster, 2013), that integrates a new set of tools that tests the extensions introduced by this new format, while also ensuring the integrity of the Collaborative Interlingual Index (CILI: Bond et al., 2016), avoiding the same new concept to be introduced through multiple projects."
}

@inproceedings{ahmadi2020multilingual,
title={{A Multilingual Evaluation Dataset for Monolingual Word Sense Alignment}},
author="Sina Ahmadi and John P. McCrae and Sanni Nimb and Thomas Troelsg\r{a}rd and Sussi Olsen and Bolette S. Pedersen and Thierry Declerck and Tanja Wissik and Monica Monachini and Andrea Bellandi and Fahad Khan and Irene Pisani and Simon Krek and Veronika Lipp and Tam\'as V\'aradi and L\'aszl\'o Simon and Andr\'as Gy\H{o}rffy and Carole Tiberius and Tanneke Schoonheim and Yifat Ben Moshe and Maya Rudich and Raya Abu Ahmad and Dorielle Lonke and Kira Kovalenko and Margit Langemets and Jelena Kallas and Oksana Dereza and Theodorus Fransen and David Cillessen and David Lindemann and Mikel Alonso and Ana Salgado and Jos\'e Luis Sancho and Rafael-J. Ure\~na-Ruiz and Kiril Simov and Petya Osenova and Zara Kancheva and Ivaylo Radev and Ranka Stankovi\'c and Cvetana  Krstev and Biljana Lazi\'c and Aleksandra Markovi\'c and Andrej Perdih and Dejan Gabrov\v{s}ek",
affiliation="['NUIG', 'NUIG', 'Society for Danish Language and Literature', 'Society for Danish Language and Literature', 'Centre for Language Technology, University of Copenhagen', 'Centre for Language Technology', 'University of Copenhagen', 'Austrian Centre for Digital Humanities', 'Austrian Centre for Digital Humanities', 'Istituto di Linguistica Computazionale {\textquotedblleft}A. Zampolli{\textendash} CNR{\textquotedblright}', 'Istituto di Linguistica Computazionale {\textquotedblleft}A. Zampolli{\textendash} CNR{\textquotedblright}', 'Istituto di Linguistica Computazionale {\textquotedblleft}A. Zampolli{\textendash} CNR{\textquotedblright}', 'Universit\`a di Pisa', 'Jo\v{z}ef Stefan Institute', 'Research Institute for Linguistics', 'Research Institute for Linguistics', 'Research Institute for Linguistics', 'Research Institute for Linguistics', 'Dutch Language Institute', 'Dutch Language Institute', 'K Dictionaries', 'K Dictionaries', 'K Dictionaries', 'K Dictionaries', 'Institute for Linguistic Studies of the Russian Academy of Sciences', 'Institute of the Estonian Language', 'Institute of the Estonian Language', 'NUIG', 'NUIG', 'NUIG', 'Euskal Herriko Unibertsitatea, Universidad del Pa{\'\i}s Vasco', 'Euskal Herriko Unibertsitatea, Universidad del Pa{\'\i}s Vasco', 'P\'ortico da L{\'\i}ngua Portuguesa', 'Centro de estudios de la Real Academia Espa\~nola', 'Centro de estudios de la Real Academia Espa\~nola', 'Bulgarian Academy of Sciences', 'Bulgarian Academy of Sciences', 'Bulgarian Academy of Sciences', 'Bulgarian Academy of Sciences', 'University of Belgrade', 'University of Belgrade', 'University of Belgrade', 'Institute for Serbian Language SASA', 'Research Centre of the Slovenian Academy of Sciences and Arts, Fran Ramov\v{s} Institute of the Slovenian Language', 'Research Centre of the Slovenian Academy of Sciences and Arts, Fran Ramov\v{s} Institute of the Slovenian Language']",
date="2020-05-11",
booktitle="Proceedings of the 12th Language Resource and Evaluation Conference (LREC 2020)",
year="2020",
url="http://www.lrec-conf.org/proceedings/lrec2020/pdf/2020.lrec-1.395.pdf",
pages="3232-3242",
description="Aligning senses across resources and languages is a challenging task with beneficial applications in the field of natural language processing and electronic lexicography. In this paper, we describe our efforts in manually aligning monolingual dictionaries. The alignment is carried out at sense-level for various resources in 15 languages. Moreover, senses are annotated with possible semantic relationships such as broadness, narrowness, relatedness, and equivalence. In comparison to previous datasets for this task, this dataset covers a wide range of languages and resources and focuses on the more challenging task of linking general-purpose language. We believe that our data will pave the way for further advances in alignment and evaluation of word senses by creating new solutions, particularly those notoriously requiring data such as neural networks. Our resources are publicly available at https://github.com/elexis-eu/MWSA."
}

@inproceedings{declerck2020recent,
title={{Recent Developments for the Linguistic Linked Open Data Infrastructure}},
author="Thierry Declerck and John Philip McCrae and Christian Chiarcos and Philipp Cimiano and Jorge Gracia and Matthias Hartung and Deirdre Lee and Elena Montiel-Ponsoda and Artem Revenko and Roser Saur{\'\i}",
affiliation="['DFKI GmbH', 'NUIG', 'Goethe-University Frankfurt', 'Bielefeld University', 'University of Zaragoza', 'Semalytix', 'Derilinx', 'Universidad Polit\'ecnica de Madrid', 'Semantic Web Company', 'Oxford University Press']",
date="2020-05-11",
booktitle="Proceedings of the 12th Language Resource and Evaluation Conference (LREC 2020)",
year="2020",
url="http://www.lrec-conf.org/proceedings/lrec2020/pdf/2020.lrec-1.695.pdf",
pages="5660-5667",
description="In this paper we describe the contributions made by the European H2020 project {\textquotedblleft}Pr\^et-\`a-LLOD{\textquotedblright} ({\textquoteleft}Ready-to-use Multilingual Linked ` Language Data for Knowledge Services across Sectors{\textquoteright}) to the further development of the Linguistic Linked Open Data (LLOD) infrastructure. Pr\^et-\`a-LLOD aims to develop a new methodology for building data value chains applicable to a wide range of sectors and ` applications and based around language resources and language technologies that can be integrated by means of semantic technologies.  We describe the methods implemented for increasing the number of language data sets in the LLOD. We also present the approach for ensuring interoperability and for porting LLOD data sets and services to other infrastructures, as well as the contribution of the projects to existing standards."
}

@inproceedings{krishan2019comparative,
title={{A Comparative Study of SVM and LSTM Deep Learning Algorithms for Stock Market Prediction}},
author="Sai Krishna Lakshminarayanan and John McCrae",
affiliation="['National University of Ireland Galway', 'National University of Ireland Galway']",
date="2019-12-05",
url="http://ceur-ws.org/Vol-2563/aics\_41.pdf",
booktitle="Proceedings for the 27th AIAI Irish Conference on Artificial Intelligence and Cognitive Science",
description="The paper presents a comparative study of the performance of Long Short-Term Memory (LSTM) neural network models with Support Vector Machine (SVM) regression models. The framework built as a part of this study comprises of eight models. In this, 4 models are built using LSTM and 4 models using SVM respectively. Two major datasets are used for this paper. One is the base standard Dow Jones Index (DJI) stock price dataset and another is the combination of this stock price dataset along with external added input parameters of crude oil and gold prices. This comparative study shows the best model in combination with our input dataset. The performance of the models is measured in terms of their Root Mean Squared Error (RMSE), Mean Squared Error (MSE), Mean Absolute Error, Mean Absolute Percentage Error (MAPE) and R squared (R2) score values. The methodologies and the results of the models are discussed and possible enhancements to this work are also provided.",
year="2019"
}

@inproceedings{mccrae2019linguistic,
title={{Linguistic Linked Open Data for All}},
author="John P. McCrae and Thierry Declerck",
affiliation="['National University of Ireland Galway', 'DFKI GmbH']",
date="2019-12-05",
url="https://lt4all.org/media/papers/O5/179.pdf",
booktitle="Proceedings of the Language Technology 4 All Conference",
description="In this paper we briefly describe the European H2020 project {\textquotedblleft}Pr\^et-\`a-LLOD{\textquotedblright} ({\textquoteleft}Ready-to-use Multilingual Linked Language Data for Knowledge Services across Sectors{\textquoteright}). This project aims to increase the uptake of language technologies by exploiting the combination of linked data and language technologies, that is Linguistic Linked Open Data (LLOD), to create ready-to-use multilingual data. Pr\^et-\`a-LLOD aims to achieve this by creating a new methodology for building data value chains applicable to a wide-range of sectors and applications and based around language resources and language technologies that can be integrated by means of semantic technologies, in particular the usage of the LLOD.",
year="2019"
}

@inproceedings{krek2019towards,
title={{Towards a Global Lexicographic Infrastructure}},
author="Simon Krek and Thierry Declerck and John Philip McCrae and Tanja Wissik",
affiliation="['Jo\v{z}ef Stefan Institute', 'DFKI GmbH', 'National University of Ireland Galway', 'Austrian Centre for Digital Humanities at the Austrian Academy of Sciences']",
date="2019-12-05",
url="https://lt4all.org/media/papers/O7/173.pdf",
booktitle="Proceedings of the Language Technology 4 All Conference",
description="In this paper we briefly describe the European project ELEXIS (European Lexicographic Infrastructure). ELEXIS aims to integrate, extend and harmonise national and regional efforts in the field of lexicography, both modern and historical, with the goal of creating a sustainable infrastructure which will enable efficient access to high quality lexical data in the digital age, and bridge the gap between more advanced and lesser-supported lexicographic resources. For this, ELEXIS makes use of or establish common standards and solutions for the development of lexicographic resources and develop strategies and tools for extracting, structuring and linking lexicographic resource",
year="2019"
}

@inproceedings{mccrae2019cardamom,
title={{Cardamom: Comparative Deep Models for Minority and Historical Languages}},
author="John Philip McCrae and Theodorus Fransen",
affiliation="['National University of Ireland Galway', 'National University of Ireland Galway']",
date="2019-12-05",
url="https://lt4all.org/media/papers/O9/159.pdf",
booktitle="Proceedings of the Language Technology 4 All Conference",
description="This paper gives an overview of the Cardamom project, which aims to close the resource gap for minority and under-resourced languages by means of deep-learning-based natural language processing (NLP) and exploiting similarities of closely-related languages. The project further extends this concept to historical languages, which can be considered as closely related to their modern form, and as such aims to provide NLP through both space and time for languages that have been ignored by current approaches.",
year="2019"
}

@inproceedings{klimek2019challenges,
title={{Challenges for the Representations for Morphology in Ontology Lexicons}},
author="Bettina Klimek and John P. McCrae and Maxim Ionov and James K. Tauber and Christian Chiarcos and Julia Bosque-Gil and Paul Buitelaar",
affiliation="['Leipzig University', 'National University of Ireland Galway', 'Goethe-University Frankfurt', 'Open Greek and Latin Project', 'Goethe-University Frankfurt', 'Universidad Polit\'ecnica de Madrid', 'National University of Ireland Galway']",
date="2019-10-03",
url="https://elex.link/elex2019/wp-content/uploads/2019/09/eLex\_2019\_33.pdf",
booktitle="Proceedings of Sixth Biennial Conference on Electronic Lexicography, eLex 2019",
description="Recent years have experienced a growing trend in the publication of language resources as Linguistic Linked Data (LLD) to enhance their discovery, reuse and the interoperability of tools that consume language data. To this aim, the OntoLex-lemon model has emerged as a de-facto standard to represent lexical data on the Web. However, traditional dictionaries contain a considerable amount of morphological information which is not straightforwardly representable as LLD within the current model. In order to fill this gap a new Morphology Module of OntoLex-lemon is currently developed. This papers presents the results of this model as on-going work as well as the underlying challenges that emerged during the module development. Based on the MMoOn Core ontology, it aims to account for a wide range of morphological information, ranging from endings to derive whole paradigms to the decomposition and generation of lexical entries which is in compliance to other OntoLex-lemon modules and facilitates the encoding of complex morphological data in ontology lexicons.",
year="2019"
}

@inproceedings{mccrae2019elexis,
title={{The ELEXIS Interface for Interoperable Lexical Resources}},
author="John P. McCrae and Carole Tiberius and Anas Fahad Khan and Ilan Kernerman and Thierry Declerck and Simon Krek and Monica Monachini and Sina Ahmadi",
affiliation="['National University of Ireland Galway', 'Instituut voor de Nederlandse Taal', 'CNR- Istituto di Linguistica Computazionale {\guillemotleft}A. Zampolli{\guillemotright}', 'K Dictionaries', 'Austrian Centre for Digital Humanities, Austrian Academy of Sciences', 'Jo\v{z}ef Stefan Institute/University of Ljubljana', 'CNR- Istituto di Linguistica Computazionale {\guillemotleft}A. Zampolli{\guillemotright}', 'National University of Ireland Galway']",
date="2019-10-03",
url="https://elex.link/elex2019/wp-content/uploads/2019/09/eLex\_2019\_37.pdf",
booktitle="Proceedings of Sixth Biennial Conference on Electronic Lexicography, eLex 2019",
description="ELEXIS is a project that aims to create a European network of lexical resources, and one of the key challenges for this is the development of an interoperable interface for different lexical resources so that further tools may improve the data. This paper describes this interface and in particular describes the five methods of entrance into the infrastructure, through retrodigitization, by conversion to TEI-Lex0, by the TEI-Lex0 format, by the OntoLex format or through the REST interface described in this paper.",
year="2019"
}

@inproceedings{ahmadi2019towards,
title={{Towards Electronic Lexicography for the Kurdish Language}},
author="Sina Ahmadi and Hossein Hassani and John P. McCrae",
affiliation="['National University of Ireland Galway', 'University of Kurdistan Hewler', 'National University of Ireland Galway']",
date="2019-10-03",
url="https://elex.link/elex2019/wp-content/uploads/2019/09/eLex\_2019\_50.pdf",
booktitle="Proceedings of Sixth Biennial Conference on Electronic Lexicography, eLex 2019",
description="This paper describes the development of lexicographic resources for Kurdish and provides a lexical model for this language. Kurdish is considered a less-resourced language, and currently, lacks the machine-readable lexicon resources. The unique potential which  Linked Data and the Semantic Web offer to e-lexicography enables interoperability across lexical resources by elevating the traditional linguistic data to machine-processable semantic formats. Therefore, we present our lexicon in Ontolex-Lemon ontology as a standard model for sharing lexical information on the Semantic Web. The research covers Sorani, Kurmanji, and Hawrami dialects of Kurdish. This research suggests that although Kurdish is a less-resourced language, in terms of documented lexicons, it owns a wide range of resources, but because they are machine-readable, they could not contribute to the language processing. The outcome of this project, which is made publicly available, assists scholars in their efforts towards making Kurdish a resource-rich language.",
year="2019"
}

@inproceedings{pereira2019taxonomy,
title={{Taxonomy Extraction for Customer Service Knowledge Base Construction}},
author="Bianca Pereira and C\'ecile Robin and Tobias Daudert and John P. McCrae and Paul Buitelaar and Pranab Mohanty",
affiliation="['National University of Ireland Galway', 'National University of Ireland Galway', 'National University of Ireland Galway', 'National University of Ireland Galway', 'National University of Ireland Galway', 'Fidelity Investments']",
booktitle="Proceedings of the SEMANTicS 2019",
description="Customer service agents play an important role in bridging the gap between customers' vocabulary and business terms. In a scenario where organisations are moving into semi-automatic customer service, semantic technologies with capacity to bridge this gap become a necessity. In this paper we explore the use of automatic taxonomy extraction from text as a means to reconstruct a customer-agent taxonomic vocabulary.  We evaluate our proposed solution in an industry use case scenario in the financial domain and show that our approaches for automated term extraction and using in-domain training for taxonomy construction can improve the quality of automatically constructed taxonomic knowledge bases.",
year="2019",
date="2019-11-04",
url="https://link.springer.com/chapter/10.1007/978-3-030-33220-4\_13"
}

@inproceedings{doyle2019character,
title={{A Character-Level LSTM Network Model for Tokenizing the Old Irish text of the W\"urzburg Glosses on the Pauline Epistles}},
author="Adrian Doyle and John P. McCrae and Clodagh Downey",
booktitle="Proceedings of the Celtic Language Technology Workshop 2019",
description="This paper examines difficulties inherent in tokenization of Early Irish texts and demonstrates that a neural-network-based approach may provide a viable solution for historical texts which contain unconventional spacing and spelling anomalies. Guidelines for tokenizing Old Irish text are presented and the creation of a character-level LSTM network is detailed, its accuracy assessed, and efforts at optimising its performance are recorded. Based on the results of this research it is expected that a character- level LSTM model may provide a viable solution for tokenization of historical texts where the use of Scriptio Continua, or alternative spacing conventions, makes the automatic separation of tokens difficult.",
year="2019",
affiliation="['National University of Ireland Galway', 'National University of Ireland Galway', 'National University of Ireland Galway']",
date="2019-08-19",
url="https://www.aclweb.org/anthology/W19-6910.pdf",
doi="10.18653/v1/w19-6910"
}

@inproceedings{mccrae2019adapting,
title={{Adapting Term Recognition to an Under-Resourced Language: the Case of Irish}},
author="John P. McCrae and Adrian Doyle",
booktitle="Proceedings of the Celtic Language Technology Workshop 2019",
description="Automatic Term Recognition (ATR) is an important method for the summarization and analysis of large corpora, and normally requires a significant amount of linguistic input, in particular the use of part-of-speech taggers. For an under-resourced language such as Irish, the resources necessary for this may be scarce or entirely absent. We evaluate two methods for the automatic extraction of terms, based on the small part-of-speech-tagged corpora that are available for Irish and on a large terminology list, and show that both methods can produce viable term extractors. We evaluate this with a newly constructed corpus that is the first available corpus for term extraction in Irish. Our results shine some light on the challenge of adapting natural language processing systems to under-resourced scenarios.",
year="2019",
affiliation="['National University of Ireland Galway', 'National University of Ireland Galway']",
date="2019-08-19",
url="https://www.aclweb.org/anthology/W19-6907.pdf",
doi="10.18653/v1/w19-6907"
}

@inproceedings{chakravarthi2019wordnet,
title={{WordNet Gloss Translation for Under-resourced Languages using Multilingual Neural Machine Translation}},
author="Bharathi Raja Chakravarthi and Mihael Arcan and John P. McCrae",
booktitle="Proceedings of the MomenT Workshop",
description="In this paper, we translate the glosses in the English WordNet based on the expand approach for improving and generating wordnets with the help of multilingual neural machine translation. Neural Machine Translation (NMT) has recently been applied to many tasks in natural language processing, leading to state-of-the-art performance. However, the performance of NMT often suffers in low resource scenarios where large corpora cannot be obtained. Using training data from closely related language have proven to be invaluable for improving performance.  In this paper, we describe how we trained multilingual NMT from closely related language utilizing phonetic transcription for Dravidian languages. We report the evaluation result of the generated wordnets sense in terms of precision. By comparing to the recently proposed approach, we show improvement in terms of precision.",
year="2019",
affiliation="['National University of Ireland Galway', 'National University of Ireland Galway', 'National University of Ireland Galway']",
date="2019-08-19",
url="https://www.aclweb.org/anthology/W19-7101.pdf",
doi="10.18653/v1/w19-7101"
}

@inproceedings{chakravarthi2019multilingual,
title={{Multilingual Multimodal Machine Translation for Dravidian Languages utilizing Phonetic Transcription}},
author="Bharathi Raja Chakravarthi and Ruba Priyadharshini and Bernardo Stearns and Arun Jayapal and S Srivedy and Mihael Arcan and Manel Zarrouk and John P. McCrae",
booktitle="Proceedings of the 2nd Workshop on Technologies for MT of Low Resource Languages (LoResMT 2019)",
description="Multimodal machine translation is the task of translating from source language to target language using information from other modalities.  Existing multimodal datasets have been restricted to only highly resourced languages. These datasets were collected by manual translation of English descriptions from the Flickr30K dataset. In this work, we introduce MMDravi, a Multilingual Multimodal dataset for under-resourced Dravidian languages. It comprises of 30K sentences which were created utilizing several machine translation outputs.  Using data from MMDravi and a phonetic transcription of the corpus, we build an MMNMT system for closely related Dravidian languages to take advantage of multilingual corpus and other modalities. We evaluate our MMNMT translations generated by the proposed approach with human annotated evaluation tests in terms of BLEU, METEOR, and TER. Relying on multilingual corpora, phonetic transcription, and image features, our approach improves the translation quality for the under-resourced languages.",
year="2019",
affiliation="['National University of Ireland Galway', 'Saraswathi Narayanan College', 'National University of Ireland Galway', 'Smart Insights from Conversations', 'Tamil Nadu Agricultural University', 'National University of Ireland Galway', 'National University of Ireland Galway', 'National University of Ireland Galway']",
date="2019-08-20",
url="https://www.aclweb.org/anthology/W19-6809.pdf",
doi="10.18653/v1/w19-6809"
}

@inproceedings{mccrae2019english,
title={{English WordNet 2019 -- An Open-Source WordNet for English}},
author="John P. McCrae and Alexandre Rademaker and Francis Bond and Ewa Rudnicka and Christiane Fellbaum",
booktitle="Proceedings of the 10th Global WordNet Conference {\textendash} GWC 2019",
description="We describe the release of a new wordnet for English based on the Princeton WordNet, but now developed under an open-source model. In particular, this version of WordNet, which we call English WordNet 2019, which has been developed by multiple people around the world through GitHub, fixes many errors in previous wordnets for English. We give some details of the changes that have been made in this version and give some perspectives about likely future changes that will be made as this project continues to evolve.",
year="2019",
affiliation="['National University of Ireland Galway', 'IBM Research and FGV/EMAp', 'Nanyang Technological University', 'Wroclaw University of Technology', 'Princeton University']",
date="2019-07-23"
}

@inproceedings{mccrae2019identification,
author="John P. McCrae",
title={{Identification of Adjective-Noun Neologisms using Pretrained Language Models}},
booktitle="Joint Workshop on Multiword Expressions and WordNet (MWE-WN 2019) at ACL 2019",
description="Neologism detection is a key task in the constructing of lexical resources and has wider implications for NLP, however the identification of multiword neologisms has received little attention. In this paper, we show that we can effectively identify the distinction between compositional and non-compositional adjective-noun pairs by using pretrained language models and comparing this with individual word embeddings. Our results show that the use of these models significantly improves over baseline linguistic features, however the combination with linguistic features still further improves the results, suggesting the strength of a hybrid approach.",
year="2019",
affiliation="['National University of Ireland Galway']",
date="2019-08-02",
url="https://www.aclweb.org/anthology/W19-5116.pdf",
doi="10.18653/v1/w19-5116"
}

@inproceedings{arcan2019inferring,
title={{Inferring translation candidates for multilingual dictionary generation}},
author="Mihael Arcan and Daniel Torregrosa and Sina Ahmadi and John P. McCrae",
booktitle="Proceedings of the 2nd Translation Inference Across Dictionaries (TIAD) Shared Task",
description="In the widely-connected digital world, multilingual lexical resources are one of the most important resources, for natural language processing applications, including information retrieval, question answering or knowledge management. These applications benefit from the multilingual knowledge as well as from the semantic relation between the words documented in these resources. Since multilingual dictionary creation and curation is a time-consuming task, we explored the use of multi-way neural machine translation trained on corpora of languages from the same family and trained additionally with a relatively small human-validated dictionary to infer new translation candidates. Our results showed not only that new dictionary entries can be identified and extracted from the translation model, but also that the expected precision and recall of the resulting dictionary can be adjusted by using different thresholds.",
affiliation="['National University of Ireland Galway', 'National University of Ireland Galway', 'National University of Ireland Galway', 'National University of Ireland Galway']",
date="2019-05-20",
year="2019",
url="http://ceur-ws.org/Vol-2493/regular1.pdf"
}

@inproceedings{torregrosa2019tiad,
title={{TIAD 2019 Shared Task: Leveraging Knowledge Graphs with Neural Machine Translation for Automatic Multilingual Dictionary Generation}},
author="Daniel Torregrosa and Mihael Arcan and Sina Ahmadi and John P. McCrae",
booktitle="Proceedings of the 2nd Translation Inference Across Dictionaries (TIAD) Shared Task",
description="This paper describes the different proposed approaches to the TIAD 2019 Shared Task, which consisted in the automatic discovery and generation of dictionaries leveraging multilingual knowledge bases. We present three methods based on graph analysis and neural machine translation and show that we can generate translations without parallel data.",
affiliation="['National University of Ireland Galway', 'National University of Ireland Galway', 'National University of Ireland Galway', 'National University of Ireland Galway']",
date="2019-05-20",
year="2019",
url="http://ceur-ws.org/Vol-2493/regular1.pdf"
}

@inproceedings{mccrae2019tiad,
title={{TIAD Shared Task 2019: Orthonormal Explicit Topic Analysis for Translation Inference across Dictionaries}},
author="John P. McCrae",
booktitle="Proceedings of the 2nd Translation Inference Across Dictionaries (TIAD) Shared Task",
description="The task of inferring translations can be achieved by the means of comparable corpora and in this paper we apply explicit topic modelling over comparable corpora to the task of inferring translation candidates. In particular, we use the Orthonormal Explicit Topic Analysis (ONETA) model, which has been shown to be the state-of-the-art explicit topic model through its elimination of correlations between topics. The method proves highly effective at selecting translations with high precision.",
affiliation="['National University of Ireland Galway']",
date="2019-05-20",
year="2019",
url="http://ceur-ws.org/Vol-2493/system4.pdf"
}

@inproceedings{ahmadi2019lexical,
title={{Lexical Sense Alignment using Weighted Bipartite b-Matching}},
author="Sina Ahmadi and Mihael Arcan and John McCrae",
booktitle="Proceedings of the Poster Track of LDK 2019",
description="Lexical resources are important components of natural language processing (NLP) applications providing linguistic information about the vocabulary of a language and the semantic relationships between the words. While there is an increasing number of lexical resources, particularly expert-made ones such as WordNet or FrameNet  as well as collaboratively- curated ones such as Wikipedia1 or Wiktionary2 , manual construction and maintenance of such resources is a cumbersome task. This can be efficiently addressed by NLP techniques.  Aligned resources have shown to improve word, knowledge and domain coverage and increase multilingualism by creating new lexical resources such as Yago , BabelNet and ConceptNet  In addition, they can improve the performance of NLP tasks such as word sense disambiguation  semantic role tagging and semantic relations extraction.",
affiliation="['National University of Ireland Galway', 'National University of Ireland Galway', 'National University of Ireland Galway', 'National University of Ireland Galway']",
date="2019-05-20",
year="2019",
url="http://ceur-ws.org/Vol-2402/paper3.pdf",
pages="12-16"
}

@inproceedings{jarrar2019representing,
title={{Representing Arabic Lexicons in Lemon - a Preliminary Study}},
author="Mustafa Jarrar and Hamzeh Amayreh and John McCrae",
booktitle="Proceedings of the Poster Track of LDK 2019",
description=" We present our progress in representing 150 Arabic multilingual lexicons using Lemon, which we have been digitizing from scratch. These lexicons are available through a lexicographic search engine (https://ontology.birzeit.edu) that allows searching for translations, synonyms, and definitions. Representing these lexicons in Lemon will enable them to be used by ontologies and NLP applications, as well as to be interlinked with the Open Linguistic Data Cloud. ",
affiliation="['Birzeit University', 'Birzeit University', 'National University of Ireland Galway']",
date="2019-05-20",
year="2019",
url="http://ceur-ws.org/Vol-2402/paper6.pdf",
pages="29-33"
}

@inproceedings{zayed2019crowd,
title={{Crowd-sourcing A High-Quality Dataset for Metaphor Identification in Tweets}},
author="Omnia Zayed and John P. McCrae and Paul Buitelaar",
booktitle="2nd Conference on Language, Data and Knowledge (LDK 2019)",
year="2019",
url="http://drops.dagstuhl.de/opus/volltexte/2019/10374/pdf/OASIcs-LDK-2019-10.pdf",
doi="10.4230/OASIcs.LDK.2019.10",
description="Metaphor is one of the most important elements of human communication, especially in informal settings such as social media. There have been a number of datasets created for metaphor identification, however, this task has proven difficult due to the nebulous nature of metaphoricity. In this paper, we present a crowd-sourcing approach for the creation of a dataset for metaphor identification, that is able to rapidly achieve large coverage over the different usages of metaphor in a given corpus while maintaining high accuracy. We validate this methodology by creating a set of 2,500 manually annotated tweets in English, for which we achieve inter-annotator agreement scores over 0.8, which is higher than other reported results that did not limit the task. This methodology is based on the use of an existing classifier for metaphor in order to assist in the identification and the selection of the examples for annotation, in a way that reduces the cognitive load for annotators and enables quick and accurate annotation. We selected a corpus of both general language tweets and political tweets relating to Brexit and we compare the resulting corpus on these two domains. As a result of this work, we have published the first dataset of tweets annotated for metaphors, which we believe will be invaluable for the development, training and evaluation of approaches for metaphor identification in tweets.",
affiliation="['National University of Ireland Galway', 'National University of Ireland Galway', 'National University of Ireland Galway', 'National University of Ireland Galway']",
date="2019-05-20"
}

@inproceedings{chakravarthi2019comparison,
author="Bharathi Raja Chakravarthi and Mihael Arcan and John P. McCrae",
title={{Comparison of Different Orthographies for Machine Translation of Under-Resourced Dravidian Languages}},
booktitle="2nd Conference on Language, Data and Knowledge (LDK 2019)",
pages="6:1--6:14",
series="OpenAccess Series in Informatics (OASIcs)",
ISBN="978-3-95977-105-4",
ISSN="2190-6807",
year="2019",
volume="70",
editor="Maria Eskevich and Gerard de Melo and Christian Fth and John P. McCrae and Paul Buitelaar and Christian Chiarcos and Bettina Klimek and Milan Dojchinovski",
publisher="Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik",
address="Dagstuhl, Germany",
url="http://drops.dagstuhl.de/opus/volltexte/2019/10370",
URN="urn:nbn:de:0030-drops-103700",
doi="10.4230/OASIcs.LDK.2019.6",
description="Under-resourced languages are a significant challenge for statistical approaches to machine translation, and recently it has been shown that the usage of training data from closely-related languages can improve machine translation quality of these languages. While languages within the same language family share many properties, many under-resourced languages are written in their own native script, which makes taking advantage of these language similarities difficult. In this paper, we propose to alleviate the problem of different scripts by transcribing the native script into common representation i.e. the Latin script or the International Phonetic Alphabet (IPA). In particular, we compare the difference between coarse-grained transliteration to the Latin script and fine-grained IPA transliteration. We performed experiments on the language pairs English-Tamil, English-Telugu, and English-Kannada translation task. Our results show improvements in terms of the BLEU, METEOR and chrF scores from transliteration and we find that the transliteration into the Latin script outperforms the fine-grained IPA transcription.",
affiliation="['National University of Ireland Galway', 'National University of Ireland Galway', 'National University of Ireland Galway', 'National University of Ireland Galway']",
date="2019-05-20"
}

@proceedings{eskevich2019ldk,
editor="Maria Eskevich and Gerard de Melo and Christian Fth and John P. McCrae and Paul Buitelaar and Christian Chiarcos and Bettina Klimek and Milan Dojchinovski",
title={{2nd Conference on Language, Data and Knowledge (LDK 2019)}},
series="OpenAccess Series in Informatics (OASIcs)",
ISBN="978-3-95977-105-4",
year="2019",
volume="70",
publisher="Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik",
address="Dagstuhl, Germany",
url="http://drops.dagstuhl.de/portals/oasics/index.php?semnr=16105",
doi="10.4230/OASIcs.LDK.2019.0"
}

@inproceedings{ahmadi2018lexicographical,
title={{On Lexicographical Networks}},
author="Sina Ahmadi and Mihael Arcan and John McCrae",
booktitle="Workshop on eLexicography: Between Digital Humanities and Artificial Intelligence",
url="https://lexdhai.insight-centre.org/Lex\_DH\_\_AI\_2018\_paper\_4.pdf",
year="2018",
description="Lexical resources are important components of natural language processing (NLP) applications providing machine-readable knowledge for various tasks. One of the most popular examples of lexical resources are lexicons. Lexicons provide linguistic information about the vocabulary of a language and the semantic relationships between the words in a pair of languages. In addition to the lexicons, there are various other types of lexical resources, particularly those which are made by experts such as WordNet, VerbNet and FrameNet and, those which are collaboratively curated such as Wikipedia and Wiktionary.",
affiliation="['National University of Ireland Galway', 'National University of Ireland Galway', 'National University of Ireland Galway', 'National University of Ireland Galway']",
date="2018-12-06"
}

@proceedings{mccrae2018ldl,
title={{6th Workshop on Linked Data in Linguistics: Towards Linguistic Data Science}},
editor="John P. McCrae and Christian Chiarcos and Thierry Declerck and Jorge Gracia and Bettina Klimek",
affiliation="['National University of Ireland, Galway', 'Goethe University Frankfurt', 'DFKI GmbH and ACDH-\"OAW', 'University of Zaragoza', 'University of Leipzig']",
date="2018-05-12",
description="Since its establishment in 2012, the Linked Data in Linguistics (LDL) workshop series has become the major forum for presenting, discussing and disseminating technologies, vocabularies, resources and experiences regarding the application of Semantic Web standards and the Linked Open Data paradigm to language resources in order to facilitate their visibility, accessibility, interoperability, reusability, enrichment, combined evaluation and integration. The LDL workshop series is organized by the Open Linguistics Working Group of the Open Knowledge Foundation, and has contributed greatly to the emergence and growth of the Linguistic Linked Open Data (LLOD) cloud. LDL workshops contribute to the discussion, dissemination and establishment of community standards that drive this development, most notably the Lemon/OntoLex model for lexical resources, as well as standards for other types of language resources still under development.  Building on our earlier success in creating and linking language resources, LDL-2018 will focus on Linguistic Data Science, i.e., research methodologies and applications building on Linguistic Linked Open Data and the existing technology and resource stack for linguistics, natural language processing and digital humanities.  LDL-2018 builds on the success of the workshop series, incl. two appearances at LREC (2014, 2016), where we attracted a large number of interested participants. As of 2016, LDL workshops alternate with our stand-alone conference on Language, Data and Knowledge (LDK). LDK-2017 was held in Galway, Ireland, as a 3-day event with 150 registrants and several satellite workshops. Continuing the LDL workshop series together with LDK is important in order to facilitate dissemination within and to receive input from the language resource community, and LREC is the obvious host conference for this purpose. LDL-2018 will be supported by the ELEXIS project on an European Lexicographic Infrastructure.",
year="2018",
publisher="European Language Resources Association",
url="http://lrec-conf.org/workshops/lrec2018/W23/pdf/book\_of\_proceedings.pdf",
series="LREC-2018 Workshop Proceedings"
}

@inproceedings{krek2018european,
title={{European Lexicographic Infrastructure (ELEXIS)}},
author="Simon Krek and John McCrae and Iztok Kosem and Tanja Wissek and Carole Tiberius and Roberto Navigli and Bolette Sandford Pedersen",
affiliation="['Jo\v{z}ef Stefan Institute', 'Insight Centre for Data Analytics, National University of Ireland Galway', 'Austrian Academy of Sciences', 'Dutch Language Institute', 'Sapienza University of Rome', 'University of Copenhagen']",
date="2018-7-21",
description="In the paper we describe a new EU infrastructure project dedicated to lexicography. The project is part of the Horizon 2020 program, with a duration of four years (2018-2022). The result of the project will be an infrastructure which will (1) enable efficient access to high quality lexicographic data, and (2) bridge the gap between more advanced and less-resourced scholarly communities working on lexicographic resources. One of the main issues addressed by the project is the fact that current lexicographic resources have different levels of (incompatible) structuring, and are not equally suitable for application in in Natural Language Processing and other fields. The project will therefore develop strategies, tools and standards for extracting, structuring and linking lexicographic resources to enable their inclusion in Linked Open Data and the Semantic Web, as well as their use in the context of digital humanities.",
booktitle="Proceedings of the XVIII EURALEX International Congress on Lexicography in Global Contexts",
year="2018",
pages="881-892",
url="http://euralex.org/wp-content/themes/euralex/proceedings/Euralex\%202018/118-4-2986-1-10-20180820.pdf"
}

@inproceedings{walsh2018constructing,
title={{Constructing an Annotated Corpus of Verbal MWEs for English}},
author="Abigail Walsh and Claire Bonial and Kristina Geeraert and John P. McCrae and Nathan Schneider and Clarissa Somers",
date="2018-08-01",
description="This paper describes the construction and annotation of a corpus of verbal MWEs for English as part of the PARSEME Shared Task 1.1 on automatic identification of verbal MWEs. The criteria for corpus selection, the categories of MWEs used, and the training process are discussed, along with the particular issues that led to revisions in edition 1.1 of the annotation guidelines. Finally, an overview of the characteristics of the final annotated corpus is presented, as well as some discussion on inter-annotator agreement.",
affiliation="['ADAPT Centre, Dublin City University', 'U.S. Army Research Laboratory', 'University of Alberta', 'Insight Centre for Data Analytics, National University of Ireland Galway', 'Georgetown University', 'Georgetown University']",
doi="10.18653/v1/W18-4921",
booktitle="Proceedings of Joint Workshop on Linguistic Annotation, Multiword Expressions and Constructions (LAW-MWE-CxG-2018)",
year="2018"
}

@inproceedings{zayed2018phrase,
title={{Phrase-Level Metaphor Identification using Distributed Representations of Word Meaning}},
author="Omnia Zayed and John P. McCrae and Paul Buitelaar",
booktitle="Proceedings of the Workshop on Figurative Language Processing",
date="2018-06-01",
description="Metaphor is an essential element of human cognition which is often used to express ideas and emotions that might be difficult to express using literal language. Processing metaphoric language is a challenging task for a wide range of applications ranging from text simplification to psychotherapy. Despite the variety of approaches that are trying to process metaphor, there is still a need for better models that mimic the human cognition while exploiting fewer resources. In this paper, we present an approach based on distributional semantics to identify metaphors on the phrase-level.  We investigated the use of different word embeddings models to identify verb-noun pairs where the verb is used metaphorically. Several experiments are conducted to show the performance of the proposed approach on benchmark datasets.",
affiliation="['Insight Centre for Data Analytics, Data Science Institute, National University of Ireland Galway', 'Insight Centre for Data Analytics, Data Science Institute, National University of Ireland Galway', 'Insight Centre for Data Analytics, Data Science Institute, National University of Ireland Galway']",
year="2018",
doi="10.18653/v1/W18-0910"
}

@article{mccrae2018linking,
journal="Cybernetics and Information Technologies",
volume="18",
number="1",
pages="109-123",
author="John P. McCrae and Paul Buitelaar",
description="Linked data has been widely recognized as an important paradigm for representing data and one of the most important aspects of supporting its use is discovery of links between datasets. For many datasets, there is a significant amount of textual information in the form of labels, descriptions and documentation about the elements of the dataset and the fundament of a precise linking is in the application of semantic textual similarity to link these datasets. However, most linking tools so far rely on only simple string similarity metrics such as Jaccard scores. We present an evaluation of some metrics that have performed well in recent semantic textual similarity evaluations and apply these to linking existing datasets",
affiliation="['Insight Centre for Data Analytics, National University of Ireland Galway', 'Insight Centre for Data Analytics, National University of Ireland Galway']",
title={{Linking Datasets Using Semantic Textual Similarity}},
url="http://www.cit.iit.bas.bg/CIT\_2018/v-18-1/10\_paper.pdf",
year="2018",
doi="10.2478/cait-2018-0010"
}

@inproceedings{doyle2018preservation,
title={{Preservation of Original Orthography in the Construction of an Old Irish Corpus}},
author="Adrian Doyle and John P. McCrae and Clodagh Downey",
booktitle="Proceedings of the 3rd Workshop for Collaboration and Computing for Under-Resourced Languages",
date="2018-05-12",
description="This paper will examine the process of creating a digital corpus based on the W\"urzburg glosses, the earliest large collection of glosses written in the Irish language. Modern editorial standards applied in publications of these glosses can alter spelling, punctuation, and even the semantic meaning of a sentence where one word is used in place of another. Therefore, an understanding of the original orthography utilised by Old Irish scribes is important in determining the orthography which should be utilised in a modern digital corpus. This paper will outline why the text of the W\"urzburg glosses as it appears in Thesaurus Palaeohibernicus is the best candidate for digitisation. The automated digitisation and proofing process of the corpus will be outlined, and details will be given of a tag-set utilised within the digital corpus in order to preserve information present in Thesaurus Palaeohibernicus as metadata.",
affiliation="['National University of Ireland Galway', 'National University of Ireland Galway', 'National University of Ireland Galway']",
year="2018",
url="http://lrec-conf.org/workshops/lrec2018/W26/pdf/20\_W26.pdf"
}

@inproceedings{declerck2018elexis,
title={{ELEXIS - European Lexicographic Infrastructure: Contributions to and from the Linguistic Linked Open Data}},
author="Thierry Declerck and John McCrae and Roberto Navigli and Ksenia Zaytseva and Tanja Wissik",
date="2018-05-12",
description="In this paper we outline the interoperability aspects of the recently started European project ELEXIS (European Lexicographic Infrastructure). ELEXIS aims to integrate, extend and harmonise national and regional efforts in the field of lexicography, both modern and historical, with the goal of creating a sustainable infrastructure which will enable efficient access to high quality lexical data in the digital age, and bridge the gap between more advanced and lesser-supported lexicographic resources. For this, ELEXIS will make use of or establish common standards and solutions for the development of lexicographic resources and develop strategies and tools for extracting, structuring and linking lexicographic resources.",
affiliation="['Austrian Centre for Digital Humanities at the Austrian Academy of Sciences and DFKI GmbH, Multilingual Technologies Lab', 'Insight Centre for Data Analytics at the National University of Ireland Galway, Ireland', 'Sapienza University of Rome', 'Austrian Centre for Digital Humanities at the Austrian Academy of Sciences', 'Austrian Centre for Digital Humanities at the Austrian Academy of Sciences']",
booktitle="Proceedings of the Globalex 2018 Workshop",
year="2018"
}

@inproceedings{sarkar2018supervised,
booktitle="Proceedings of the 11th Language Resource and Evaluation Conference (LREC)",
year="2018",
author="Rajdeep Sarkar and John P. McCrae and Paul Buitelaar",
date="2018-05-12",
description="Large collections of texts are commonly generated by large organizations and making sense of these collections of texts is a significant challenge. One method for handling this is to organize the concepts into a hierarchical structure such that similar concepts can be discovered and easily browsed. This approach was the subject of a recent evaluation campaign, TExEval, however the results of this task showed that none of the systems consistently outperformed a relatively simple baseline.In order to solve this issue, we propose a new method that uses supervised learning to combine multiple features with a support vector machine classifier including the baseline features. We show that this outperforms the baseline and thus provides a stronger method for identifying taxonomic relations than previous methods",
affiliation="['Indian Institute of Technology Kharagpur', 'Insight Centre for Data Analytics, National University of Ireland Galway', 'Insight Centre for Data Analytics, National University of Ireland Galway']",
title={{A supervised approach to taxonomy extraction using word embeddings}},
url="http://www.lrec-conf.org/proceedings/lrec2018/pdf/601.pdf"
}

@inproceedings{wood2018comparison,
booktitle="Proceedings of the 11th Language Resource and Evaluation Conference (LREC)",
year="2018",
author="Ian Wood and John P. McCrae and Vladimir Andryushechkin and Paul Buitelaar",
title={{A Comparison Of Emotion Annotation Schemes And A New Annotated Data Set}},
date="2018-05-12",
description="While the recognition of positive/negative sentiment in text is an established task with many standard data sets and well developed methodologies, the recognition of more nuanced affect has received less attention, and in particular, there are very few publicly available gold standard annotated resources. To address this lack, we present a series of emotion annotation studies on tweets culminating in a publicly available collection of 2,019 tweets with scores on four emotion dimensions: valence, arousal, dominance and surprise, following the emotion representation model identified by Fontaine et.al. (Fontaine et al., 2007). Further, we make a comparison of relative vs. absolute annotation schemes. We find improved annotator agreement with a relative annotation scheme (comparisons) on a dimensional emotion model over a categorical annotation scheme on Ekman{\textquoteright}s six basic emotions (Ekman et al., 1987), however when we compare inter-annotator agreement for comparisons with agreement for a rating scale annotation scheme (both with the same dimensional emotion model), we find improved inter-annotator agreement with rating scales, challenging a common belief that relative judgements are more reliable.",
affiliation="['Insight Centre for Data Analytics, National University of Ireland Galway', 'Insight Centre for Data Analytics, National University of Ireland Galway', 'Insight Centre for Data Analytics, National University of Ireland Galway', 'Insight Centre for Data Analytics, National University of Ireland Galway']",
url="http://www.lrec-conf.org/proceedings/lrec2018/pdf/61.pdf"
}

@inproceedings{ziad2018linked,
booktitle="Proceedings of the 11th Language Resource and Evaluation Conference (LREC)",
year="2018",
author="Housam Ziad and John P. McCrae and Paul Buitelaar",
date="2018-05-12",
description="In this paper, we describe Teanga, a linked data based platform for natural language processing (NLP). Teanga enables the use of many NLP services from a single interface, whether the need was to use a single service or multiple services in a pipeline. Teanga focuses on the problem of NLP services interoperability by using linked data to define the types of services input and output. Teanga{\textquoteright}s strengths include being easy to install and run, easy to use, able to run multiple NLP tasks from one interface and helping users to build a pipeline of tasks through a graphical user interface.",
affiliation="['Insight Centre for Data Analytics, National University of Ireland, Galway', 'Insight Centre for Data Analytics, National University of Ireland, Galway', 'Insight Centre for Data Analytics, National University of Ireland, Galway']",
title={{Teanga: A Linked Data based platform for Natural Language Processing}},
url="http://www.lrec-conf.org/proceedings/lrec2018/pdf/106.pdf"
}

@inproceedings{arcan2018automatic,
booktitle="Proceedings of the 11th Language Resource and Evaluation Conference (LREC)",
year="2018",
author="Mihael Arcan and Elena Montiel-Ponsoda and John P. McCrae and Paul Buitelaar",
title={{Automatic Enrichment of Terminological Resources: the IATE RDF Example}},
date="2018-05-12",
description="Terminological resources have proven necessary in many organizations and institutions to ensure communication between experts. However, the maintenance of these resources is a very time-consuming and expensive process. Therefore, the work described in this contribution aims to automate the maintenance process of such resources. As an example, we demonstrate enriching the RDF version of IATE with new terms in the languages for which no translation was available, as well as with domain-disambiguated sentences and information about usage frequency. This is achieved by relying on machine translation trained on parallel corpora that contains the terms in question and multilingual word sense disambiguation performed on the context provided by the sentences. Our results show that for most languages translating the terms within a disambiguated context significantly outperforms the approach with randomly selected sentences.",
affiliation="['Insight Centre for Data Analytics, National University of Ireland Galway', 'Ontology Engineering Group, Universidad Politecnica de Madrid', 'Insight Centre for Data Analytics, National University of Ireland Galway', 'Insight Centre for Data Analytics, National University of Ireland Galway']",
url="http://www.lrec-conf.org/proceedings/lrec2018/summaries/541.html"
}

@article{buitelaar2018mixedemotions,
journal="IEEE Transactions on Multimedia",
year="2018",
author="Paul Buitelaar and Ian D. Wood and Sapna Negi and Mihael Arcan and John P. McCrae and Andrejs Abele and C\'ecile Robin and Vladimir Andryushechkin and Housam Ziad and Hesam Sagha and J. Fernando S\'anchez-Rada and Carlos A. Iglesias and Carlos Navarro and Andreas Giefer and Nicolaus Heise and Vincenzo Masucci and Francesco A. Danza and Ciro Caterino and Pavel Smr\v{z} and Michal Hradi\v{s} and Filip Povoln\'y and Marek Klime\v{s} and Pavel Mat\v{e}jka and Giovanni Tummarello",
date="2018-09-01",
description="Recently, there is an increasing tendency to embed functionalities for recognizing emotions from user-generated media content in automated systems such as call-centre operations, recommendations, and assistive technologies, providing richer and more informative user and content profiles. However, to date, adding these functionalities was a tedious, costly, and time-consuming effort, requiring identification and integration of diverse tools with diverse interfaces as required by the use case at hand. The MixedEmotions Toolbox leverages the need for such functionalities by providing tools for text, audio, video, and linked data processing within an easily integrable plug-and-play platform. These functionalities include: 1) for text processing: emotion and sentiment recognition; 2) for audio processing: emotion, age, and gender recognition; 3) for video processing: face detection and tracking, emotion recognition, facial landmark localization, head pose estimation, face alignment, and body pose estimation; and 4) for linked data: knowledge graph integration. Moreover, the MixedEmotions Toolbox is open-source and free. In this paper, we present this toolbox in the context of the existing landscape, and provide a range of detailed benchmarks on standard test-beds showing its state-of-the-art performance. Furthermore, three real-world use cases show its effectiveness, namely, emotion-driven smart TV, call center monitoring, and brand reputation analysis.",
affiliation="['National University of Ireland Galway', 'National University of Ireland Galway', 'National University of Ireland Galway', 'National University of Ireland Galway', 'National University of Ireland Galway', 'National University of Ireland Galway', 'National University of Ireland Galway', 'National University of Ireland Galway', 'National University of Ireland Galway', 'University of Passau', 'GSI Universidad Polit\'ecnica de Madrid', 'GSI Universidad Polit\'ecnica de Madrid', 'Paradigma Digital', 'Deutsche Welle', 'Deutsche Welle', 'Expert Systems', 'Expert Systems', 'Expert Systems', 'Brno University of Technology', 'Brno University of Technology', 'Phonexia', 'Phonexia', 'Phonexia', 'Siren Solutions']",
title={{MixedEmotions: An Open-Source Toolbox for Multi-Modal Emotion Analysis}},
url="http://ieeexplore.ieee.org/document/8269329/",
volume="20",
number="9",
doi="10.1109/TMM.2018.2798287"
}

@inproceedings{mccrae2018mapping,
booktitle="Proceedings of the 9th Global WordNet Conference",
year="2018",
author="John P. McCrae",
date="2018-01-12",
description="Lexical resource differ from encyclopaedic resources and represent two distinct types of resource covering general language and named entities respectively.  However, many lexical resources, including Princeton WordNet, contain many proper nouns, referring to named entities in the world yet it is not possible or desirable for a lexical resource to cover all named entities that may reasonably occur in a text. In this paper, we propose that instead of including synsets for instance concepts PWN should instead provide links to Wikipedia articles describing the concept. In order to enable this we have created a gold-quality mapping between all of the 7,742 instances in PWN and Wikipedia (where such a mapping is possible). As such, this resource aims to provide a gold standard for link discovery, while also allowing PWN to distinguish itself from other resources such as DBpedia or BabelNet. Moreover, this linking connects PWN to the Linguistic Linked Open Data cloud, thus creating a richer, more usable resource for natural language processing.",
affiliation="['Insight Centre for Data Analytics, National University of Ireland Galway']",
title={{Mapping WordNet Instances to Wikipedia}}
}

@inproceedings{mccrae2018towards,
booktitle="Proceedings of the 9th Global WordNet Conference",
year="2018",
author="John P. McCrae and Ian Wood and Amanda Hicks",
title={{Towards a Crowd-Sourced WordNet for Colloquial English}},
date="2018-01-12",
description="Princeton WordNet is one of the most widely-used resources for natural language processing, but is updated only infrequently and cannot keep up with the fast-changing usage of the English language on social media platforms such as Twitter. The Colloquial WordNet aims to provide an open platform whereby anyone can contribute, while still following the structure of WordNet. Many crowdsourced lexical resources often have significant quality issues, and as such care must be taken in the design of the interface to ensure quality. In this paper, we present the development of a platform that can be opened on the Web to any lexicographer who wishes to contribute to this resource and the lexicographic methodology applied by this interface",
affiliation="['Insight Centre for Data Analytics, National University of Ireland Galway', 'Insight Centre for Data Analytics, National University of Ireland Galway', 'Health Outcomes \& Policy, University of Florida']"
}

@inproceedings{chakravarthi2018improving,
booktitle="Proceedings of the 9th Global WordNet Conference",
year="2018",
author="Bharathi Raja Chakravarthi and Mihael Arcan and John P. McCrae",
title={{Improving Wordnets for Under-Resourced Languages Using Machine Translation information}},
date="2018-01-12",
description="Wordnets are extensively used in natural language processing, but the current approaches for manually building a wordnet from scratch involves large research groups for a long period of time, which are typically not available for under-resourced languages. Even if wordnet-like resources are available for under-resourced languages, they are often not easily accessible, which can alter the results of applications using these resources. Our proposed method presents an expand approach for improving and generating wordnets with the help of machine translation. We apply our methods to improve and extend wordnets for the Dravidian languages, i.e., Tamil, Telugu, Kannada, which are severly under-resourced languages. We report evaluation results of the generated wordnet senses in term of precision for these languages. In addition to that, we carried out a manual evaluation of the translations for the Tamil language, where we demonstrate that our approach can aid in improving wordnet resources for under-resourced Dravidian languages.",
affiliation="['Insight Centre for Data Analytics, National University of Ireland Galway', 'Insight Centre for Data Analytics, National University of Ireland Galway', 'Insight Centre for Data Analytics, National University of Ireland Galway']"
}

@inproceedings{pedersen2018elexis,
booktitle="Proceedings of the 9th Global WordNet Conference",
year="2018",
author="Bolette Pedersen and John McCrae and Carole Tiberius and Simon Krek",
title={{ELEXIS - a European infrastructure fostering cooperation and infor-mation exchange among lexicographical research communities}},
date="2018-01-12",
description="The paper describes objectives, concept and methodology for ELEXIS, a European infrastructure fostering cooperation and information exchange among lexicographical research communities. The infrastructure is a newly granted project under the Horizon 2020 INFRAIA call, with the topic Integrating Activities for Starting Communities. The project is planned to start in January 2018",
affiliation="['University of Copenhagen', 'National University of Ireland Galway', ' Dutch Language Institute', ' Jo\v{z}ef Stefan Institute']"
}

@inproceedings{mccrae2018mapping,
booktitle="Proceedings of the 9th Global WordNet Conference",
year="2018",
author="John P. McCrae",
title={{Mapping WordNet Instances to Wikipedia}}
}

@inproceedings{mccrae2018towards,
booktitle="Proceedings of the 9th Global WordNet Conference",
year="2018",
author="John P. McCrae and Ian Wood and Amanda Hicks",
title={{Towards a Crowd-Sourced WordNet for Colloquial English}}
}

@inproceedings{pedersen2018elexis,
booktitle="Proceedings of the 9th Global WordNet Conference",
year="2018",
author="Bolette Pedersen and John McCrae and Carole Tiberius and Simon Krek",
title={{ELEXIS - a European infrastructure fostering cooperation and infor-mation exchange among lexicographical research communities}}
}

@proceedings{vanerp2017knowledge,
editor="Marieke van Erp and Sebastian Hellmann and John P. McCrae and Christian Chiarcos and Key-Sun Choi and Jorge Gracia and Yoshihiko Hayashi and Seiji Koide and Pablo Mendes and Heiko Paulheim and Hideaki Takeda",
title={{Knowledge Graphs and Language Technology - ISWC 2016 International Workshops: KEKI and NLP\&DBpedia}},
year="2017",
url="http://www.springer.com/gp/book/9783319687223",
publisher="Springer",
series="Lecture Notes in Computer Science"
}

@proceedings{gracia2017language,
editor="Jorge Gracia and Francis Bond and John P. McCrae and Paul Buitelaar and Christian Chiarcos and Sebastian Hellmann",
title={{Language, Data, and Knowledge}},
year="2017",
url="http://www.springer.com/gp/book/9783319598871",
publisher="Springer",
series="Lecture Notes in Artificial Intelligence"
}

@inproceedings{mccrae2017linking,
title={{Linking Knowledge Graphs across Languages with Semantic Similarity and Machine Translation}},
author="John P. McCrae and Mihael Arcan and Paul Buitleaar",
year="2017",
booktitle="Proceedings of the First Workshop on Multi-Language Processing in a Globalising World (MLP2017)"
}

@inproceedings{mccrae2017ontolex,
title={{The OntoLex-Lemon Model: development and applications}},
author="John P. McCrae and Julia Bosque-Gil and Jorge Gracia and Paul Buitelaar and Philipp Cimiano",
year="2017",
booktitle="Proceedings of eLex 2017",
pages="587-597",
url="https://elex.link/elex2017/wp-content/uploads/2017/09/paper36.pdf"
}

@inproceedings{klimek2017onlit,
title={{OnLiT: An Ontology for Linguistic Terminology}},
author="Bettina Klimek and John P. McCrae and Christian Chiarcos and Sebastian Hellmann",
year="2017",
booktitle="Proceedings of the First Conference on Language, Data and Knowledge (LDK2017)",
pages="42-57",
doi="10.1007/978-3-319-59888-8\_4"
}

@inproceedings{mccrae2017colloquial,
title={{The Colloquial WordNet: Extending Princeton WordNet with Neologisms}},
author="John P. McCrae and Ian Wood and Amanda Hicks",
year="2017",
booktitle="Proceedings of the First Conference on Language, Data and Knowledge (LDK2017)",
pages="194-202",
doi="10.1007/978-3-319-59888-8\_17"
}

@inproceedings{abele2017evaluation,
title={{An Evaluation Dataset for Linked Data Profiling}},
author="Andrejs Abele and John P. McCrae and Paul Buitelaar",
year="2017",
booktitle="Proceedings of the First Conference on Language, Data and Knowledge (LDK2017)",
pages="1-9",
doi="10.1007/978-3-319-59888-8\_1"
}

@misc{cimiano2016lexicon,
title={{Lexicon Model for Ontologies: Community Report}},
author="Philipp Cimiano and John P. McCrae and Paul Buitelaar",
url="https://www.w3.org/2016/05/ontolex/",
year="2016",
organization="W3C"
}

@inproceedings{arcan2016expanding,
author="Mihael Arcan and John P. McCrae and Paul Buitelaar",
year="2016",
title={{Expanding wordnets to new languages with multilingual sense disambiguation}},
booktitle="Proceedings of The 26th International Conference on Computational Linguistics",
url="https://www.aclweb.org/anthology/C/C16/C16-1010.pdf"
}

@inproceedings{mccrae2016identifying,
author="John P. McCrae and Narumol Prangnawarat",
year="2016",
title={{Identifying Poorly-Defined Concepts in WordNet with Graph Metrics}},
booktitle="Proceedings of the First Workshop on Knowledge Extraction and Knowledge Integration (KEKI-2016)",
doi="10.1007/978-3-319-68723-0\_6"
}

@inproceedings{mccrae2016lixr,
author="John P. McCrae and Philipp Cimiano",
year="2016",
title={{LIXR: Quick, succinct conversion of XML to RDF}},
booktitle="Proceedings of the ISWC 2016 Posters and Demo Track"
}

@inproceedings{mccrae2016yuzu,
author="John P. McCrae",
year="2016",
title={{Yuzu: Publishing Any Data as Linked Data}},
booktitle="Proceedings of the ISWC 2016 Posters and Demo Track"
}

@inproceedings{mccrae2016nuig,
author="John P. McCrae and Kartik Asooja and Nitish Aggarwal and Paul Buitelaar",
year="2016",
title={{NUIG-UNLP at SemEval-2016 Task 1: Soft Alignment and Deep Learning~for Semantic Textual Similarity}},
booktitle="SemEval-2016",
url="https://aclweb.org/anthology/S/S16/S16-1110.pdf",
doi="10.18653/v1/s16-1110"
}

@inproceedings{mccrae2016linked,
author="John P. McCrae and Georgeta Bordea and Paul Buitelaar",
year="2016",
title={{Linked Data and Text Mining as an Enabler for Reproducible Research}},
booktitle="1st Workshop on Cross-Platform Text Mining and Natural Language Processing Interoperability",
url="http://interop2016.github.io/pdf/INTEROP-7.pdf"
}

@article{mccrae2016domain,
url="http://www.sciencedirect.com/science/article/pii/S1570826815001420",
title={{Domain adaptation for ontology localization}},
author="John P. McCrae and Mihael Arcan and Kartik Asooja and Jorge Gracia and Paul Buitelaar and Philipp Cimiano",
journal="Web Semantics",
volume="36",
pages="23-31",
year="2016",
doi="10.2139/ssrn.3199218"
}

@inproceedings{mccrae2016representing,
author="John P. McCrae and Philipp Cimiano and Paul Buitelaar and Georgeta Bordea",
title={{Representing Multiword Expressions on the Web with the OntoLex-Lemon model}},
booktitle="PARSEME/ENeL workshop on MWE e-lexicons",
url="http://typo.uni-konstanz.de/parseme/images/Meeting/2016-04-07-Struga-meeting/WG1-MCCRAE-ETAL-abstract.pdf",
year="2016"
}

@inproceedings{mccrae2016open,
author="John P. McCrae and Christian Chiarcos and Francis Bond and Philipp Cimiano and Thierry Declerck and Gerard de Melo and Jorge Gracia and Sebastian Hellmann and Bettina Klimek and Steven Moran and Petya Osenova and Antonio Pareja-Lora and Jonathan Pool",
title={{The Open Linguistics Working Group: Developing the Linguistic Linked Open Data Cloud}},
booktitle="10th Language Resource and Evaluation Conference (LREC)",
url="http://www.lrec-conf.org/proceedings/lrec2016/pdf/851\_Paper.pdf",
pages="2435-2441",
year="2016"
}

@inproceedings{bond2016cili,
url="https://www.overleaf.com/read/rsnvsbdghybg",
title={{CILI: the Collaborative Interlingual Index}},
author="Francis Bond and Piek Vossen and John P. McCrae and Christiane Fellbaum",
booktitle="Proceedings of the Global WordNet Conference 2016",
year="2016"
}

@inproceedings{vossen2016toward,
url="https://www.overleaf.com/read/fwhzzvrrwrmw",
title={{Toward a truly multilingual Global Wordnet Grid}},
author="Piek Vossen and Francis Bond and John P. McCrae",
booktitle="Proceedings of the Global WordNet Conference 2016",
year="2016"
}

@article{mccrae2015multilingual,
title={{Multilingual Linked Data (editorial)}},
author="John P. McCrae and Steven Moran and Sebastian Hellmann and Martin Br\"ummer",
journal="Semantic Web",
volume="6",
number="4",
pages="315-317",
year="2015",
url="http://semantic-web-journal.net/content/multilingual-linked-data",
doi="10.3233/sw-150178"
}

@article{ecklekohler2015,
title={{lemonUby - a large, interlinked, syntactically-rich lexical resource for ontologies}},
author="Judith Eckle-Kohler and John McCrae and Christian Chiarcos",
journal="Semantic Web",
volume="6",
number="4",
pages="371-378",
year="2015",
url="http://www.semantic-web-journal.net/content/lemonuby-large-interlinked-syntactically-rich-lexical-resource-ontologies-1",
doi="10.3233/sw-140159"
}

@inproceedings{mccrae2015linghub,
title={{Linghub: a Linked Data based portal supporting the discovery of language resources}},
author="John P. McCrae and Philipp Cimiano",
booktitle="Proceedings of the 11th International Conference on Semantic Systems",
pages="88-91",
year="2015"
}

@inproceedings{siemoneit2015linking,
title={{Linking Four Heterogeneous Language Resources as Linked Data}},
author="Benjamin Siemoneit and John P. McCrae and Philipp Cimiano",
booktitle="Proceedings of the 4th Workshop on Linked Data in Linguistics",
year="2015",
pages="59-63",
url="http://www.aclweb.org/anthology/W15-4207",
doi="10.18653/v1/w15-4207"
}

@inproceedings{mccrae2015reconciling,
title={{Reconciling Heterogeneous Descriptions of Language Resources}},
author="John P. McCrae and Philipp Cimiano and Victor Rodriguez-Doncel and Daniel Vila-Suero and Jorge Gracia and Luca Matteis and Roberto Navigli and Andrejs Abele and Gabriela Vulcu and Paul Buitelaar",
booktitle="Proceedings of the 4th Workshop on Linked Data in Linguistics",
year="2015",
pages="39-48",
url="http://www.aclweb.org/anthology/W/W15/W15-4205.pdf",
doi="10.18653/v1/w15-4205"
}

@inproceedings{cimiano2015linked,
title={{Linked Terminology: Applying Linked Data Principles to Terminological Resources}},
author="Philipp Cimiano and John P. McCrae and Victor Rodriguez-Doncel and Tatiana Gornostaya and Asuncion G\'omez-P\'erez and Benjamin Siemoneit and Andis Lagzdins",
booktitle="Proceedings of eLex 2015",
year="2015",
pages="504-517",
url="https://elex.link/elex2015/proceedings/eLex\_2015\_34\_Cimiano+etal.pdf"
}

@inproceedings{mccrae2015metashare,
title={{One ontology to bind them all: The META-SHARE OWL ontology for the interoperability of linguistic datasets on the Web}},
author="John P. McCrae and Penny Labropoulou and Jorge Gracia and Marta Villegas and Victor Rodriguez-Doncel and Philipp Cimiano",
booktitle="Proceedings of the 4th Workshop on the Multilingual Semantic Web",
year="2015",
url="http://ceur-ws.org/Vol-1532/paper4.pdf",
doi="10.1007/978-3-319-25639-9\_42"
}

@inproceedings{fiorelli2015lime,
title={{LIME: the Metadata Module for OntoLex}},
author="Manuel Fiorelli and Armando Stellato and John P. McCrae and Philipp Cimiano and Maria Teresa Pazienza",
booktitle="Proceedings of 12th Extended Semantic Web Conference",
year="2015",
url="http://link.springer.com/chapter/10.1007/978-3-319-18818-8\_20\#page-1",
doi="10.1007/978-3-319-18818-8\_20"
}

@incollection{gracia2015language,
url="http://link.springer.com/chapter/10.1007/978-3-319-17966-7\_1",
title={{Language Resources and Linked Data: A Practical Perspective}},
author="Jorge Gracia and Daniel Vila-Suero and John P. McCrae and Tiziano Flati and Ciro Baron and Milan Dojchinovski",
booktitle="Knowledge Engineering and Knowledge Management",
publisher="Springer",
year="2015"
}

@incollection{mccrae2014design,
url="http://link.springer.com/chapter/10.1007\%2F978-3-662-43585-4\_2\#page-1",
title={{Design Patterns for Engineering the Ontology-Lexicon Interface}},
author="John P. McCrae and Christina Unger",
booktitle="Towards the Multilingual Semantic Web",
editor="Paul Buitelaar and Philipp Cimiano",
pages="15-30",
publisher="Springer",
year="2014",
doi="10.1007/978-3-662-43585-4\_2"
}

@inproceedings{borin2014representing,
url="http://ceur-ws.org/Vol-1272/paper\_82.pdf",
title={{Representing Swedish Lexical Resources in RDF with lemon}},
author="Lars Borin and Dana Dannells and Markus Forsberg and John P. McCrae",
booktitle="Proceedings of the ISWC 2014 Posters \& Demonstrations Track - a track within the 13th International Semantic Web Conference",
pages="329-332",
year="2014"
}

@inproceedings{mccrae2014towards,
url="http://ceur-ws.org/Vol-1215/paper-05.pdf",
title={{Towards assured data quality and validation by data certification}},
author="John P. McCrae and Cord Wiljes and Philipp Cimiano",
booktitle="Proceedings of the 1st Workshop on Linked Data Quality",
year="2014"
}

@inproceedings{mccrae2014bielefeld,
url="http://alt.qcri.org/semeval2014/cdrom/pdf/SemEval016.pdf",
title={{Bielefeld SC: Orthonormal Topic Modelling for Grammar Induction}},
author="John P. McCrae and Philipp Cimiano",
booktitle="Proceedings of the 8th International Workshop on Semantic Evaluation",
year="2014",
doi="10.1007/978-3-319-59888-8\_17"
}

@inproceedings{quattri2014default,
url="http://www.aclweb.org/anthology/W/W14/W14-47.pdf\#page=152",
title={{Default Physical Measurements in SUMO}},
author="Francesca Quattri and Adam Pease and John P. McCrae",
booktitle="Proceedings of 4th Workshop on Cognitive Aspects of the Lexicon",
year="2014",
doi="10.1007/978-3-319-59888-8\_17"
}

@inproceedings{mccrae2014modelling,
url="http://anthology.aclweb.org/W/W14/W14-47.pdf\#page=212",
title={{Modelling the Semantics of Adjectives in the Ontology-Lexicon Interface}},
author="John P. McCrae and Christina Unger and Francesca Quattri and Philipp Cimiano",
booktitle="Proceedings of 4th Workshop on Cognitive Aspects of the Lexicon",
year="2014",
doi="10.1007/978-3-319-59888-8\_17"
}

@inproceedings{mccrae2014publishing,
url="https://github.com/jmccrae/wn-rdf-paper/raw/master/rdf-wordnet.pdf",
title={{Publishing and Linking WordNet using lemon and RDF}},
author="John P. McCrae and Christiane Fellbaum and Philipp Cimiano",
booktitle="Proceedings of the 3rd Workshop on Linked Data in Linguistics",
year="2014"
}

@inproceedings{ehrmann2014multilingual,
title={{A Multilingual Semantic Network as Linked Data: lemon-BabelNet}},
author="Maud Ehrmann and Francesco Ceconi and Daniela Vannella and John P. McCrae and Philipp Cimiano and Roberto Navigli",
booktitle="Proceedings of the 3rd Workshop on Linked Data in Linguistics",
year="2014"
}

@inproceedings{ehrmann2014representing,
title={{Representing Multilingual Data as Linked Data: the Case of BabelNet 2.0}},
author="Maud Ehrmann and Francesco Ceconi and Daniela Vannella and John P. McCrae and Philipp Cimiano and Roberto Navigli",
booktitle="Proceedings of the 9th Language Resource and Evaluation Conference",
pages="401-408",
year="2014"
}

@inproceedings{vilasuero20143ld,
title={{3LD: Towards high quality, industry-ready Linguistic Linked Linguistic Data}},
author="Daniel Vila-Suero and Victor Rodriguez-Doncel and Asunci\'on G\'omez-P\'erez and Philipp Cimiano and John P. McCrae and Guadalupe Aguado-de-Cea",
booktitle="European Data Forum 2014",
year="2014"
}

@book{cimiano2014ontology,
url="http://www.morganclaypool.com/doi/abs/10.2200/S00561ED1V01Y201401HLT024",
title={{Ontology-based interpretation of natural language}},
author="Philipp Cimiano and Christina Unger and John McCrae",
publisher="Morgan \& Claypool",
year="2014",
doi="10.1007/978-3-319-59888-8\_17"
}

@inproceedings{mccrae2013orthonormal,
url="https://www.aclweb.org/anthology/D/D13/D13-1179.pdf",
title={{Orthonormal explicit topic analysis for cross-lingual document matching}},
author="John McCrae and Philipp Cimiano and Roman Klinger",
booktitle="Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing",
pages="1732-1742",
year="2013"
}

@inproceedings{unger2013lemon,
url="http://ceur-ws.org/Vol-1064/Unger\_lemon.pdf",
title={{A lemon lexicon for DBpedia}},
author="Christina Unger and John McCrae and Sebastian Walter and Sara Winter and Philipp Cimiano",
booktitle="Proceedings of 1st International Workshop on NLP and DBpedia",
year="2013"
}

@inproceedings{montiel2013multilingual,
url="https://lipn.univ-paris13.fr/tia2013/Proceedings/actesTIA2013.pdf",
title={{Multilingual variation in the context of linked data}},
author="Elena Montiel-Ponsoda and John McCrae and Guadalupe Aguado-de-Cea and Jorge Gracia",
booktitle="Proceedings of the 10th International Conference on Terminology and Artificial Intelligence",
pages="19-26",
year="2013"
}

@inproceedings{mccrae2013mining,
url="http://www.aclweb.org/anthology/W/W13/W13-52.pdf\#page=20",
title={{Mining translations from the web of open linked data}},
author="John P. McCrae and Philipp Cimiano",
booktitle="Proceedings of the Joint Workshop on NLP\&LOD and SWAIE: Semantic Web, Linked Open Data and Infromation Extraction",
pages="9-13",
year="2013"
}

@inproceedings{menke2013releasing,
url="http://anthology.aclweb.org/W/W13/W13-5507.pdf",
title={{Releasing multimodal data as Linguistic Linked Open Data: An experience report}},
author="Peter Menke and John P. McCrae and Philipp Cimiano",
booktitle="Proceedings of the 2nd Workshop on Linked Data in Linguistics",
pages="44-52",
year="2013"
}

@incollection{chiarcos2013towards,
title={{Towards open data for linguistics: Lexical Linked Data}},
author="Christian Chiarcos and John McCrae and Philipp Cimiano and Christiane Fellbaum",
booktitle="New Trends of Research in Ontologies and Lexical Resources",
pages="7-25",
publisher="Springer",
year="2013",
doi="10.1007/978-3-642-31782-8\_2"
}

@incollection{cimiano2013role,
title={{On the role of senses in the Ontology-Lexicon}},
author="Philipp Cimiano and John McCrae and Paul Buitelaar and Elena Montiel-Ponsoda",
booktitle="New Trends of Research in Ontologies and Lexical Resources",
pages="43-62",
publisher="Springer",
year="2013",
doi="10.1007/978-3-319-59888-8\_17"
}

@inproceedings{spohr2012using,
url="http://nadir.uc3m.es/feosw2012/proceedings/FEOSWp1.pdf",
title={{Using SPIN to formalize accounting regulation on the Semantic Web}},
author="Dennis Spohr and Philipp Cimiano and John McCrae and Sean O'Riain",
booktitle="First International Workshop on Finance and Economics on the Semantic Web in conjunction with 9th Extended Semantic Web Conference",
pages="1-15",
year="2012",
doi="10.1007/978-3-319-59888-8\_17"
}

@inproceedings{mccrae2012collaborative,
url="http://www.lrec-conf.org/proceedings/lrec2012/pdf/544\_Paper.pdf",
title={{Collaborative semantic editing of linked data lexica}},
author="John McCrae and Elena Montiel-Ponsoda and Philipp Cimiano",
booktitle="Proc. of the 2012 International Conference on Language Resource and Evaluation",
pages="2619-2625",
year="2012"
}

@inproceedings{mccrae2012three,
title={{Three steps for creating high quality ontology-lexica}},
author="John McCrae and Philipp Cimiano",
booktitle="Proc. of the Workshop on Collaborative Resource Development and Delivery at the 2012 International Conference on Language Resource and Evaluation",
year="2012"
}

@incollection{mccrae2013integrating,
title={{Integrating WordNet and Wiktionary with lemon}},
author="John McCrae and Philipp Cimiano and Elena Montiel-Ponsoda",
booktitle="Linked Data and Linguistics",
editor="Christian Chiarcos and Sebastian Nordhoff and Sebastian Hellmann",
pages="25-34",
publisher="Springer",
year="2012",
doi="10.1007/978-3-319-59888-8\_17"
}

@article{mccrae2012interchanging,
title={{Interchanging lexical resources on the Semantic Web}},
author="John McCrae and Guadalupe Aguado-de-Cea and Paul Buitelaar and Philipp Cimiano and Thierry Declerck and Asunci\'on G\'omez-P\'erez and Jorge Gracia and Laura Hollink and Elena Montiel-Ponsoda and Dennis Spohr and Tobias Wunner",
journal="Language Resources and Evaluation",
volume="46",
number="6",
pages="701-709",
year="2012",
doi="10.1007/978-3-319-59888-8\_17"
}

@article{cimiano2011lexinfo,
title={{LexInfo: A declarative model for the lexicon-ontology interface}},
author="Philipp Cimiano and Paul Buitelaar and John McCrae and Michael Sintek",
journal="Web Semantics: Science, Services and Agents on the World Wide Web",
volume="9",
number="1",
pages="29-51",
year="2011",
doi="10.1007/978-3-319-59888-8\_17"
}

@article{gracia2011challenges,
url="http://oa.upm.es/8848/1/Multiling.pdf",
title={{Challenges for the Multilingual Web of Data}},
author="Jorge Gracia and Elena Montiel-Ponsoda and Philipp Cimiano and Asunci\'on G\'omez-P\'erez and Paul Buitelaar and John McCrae",
journal="Web Semantics: Science, Services and Agents on the World Wide Web",
number="11",
pages="63-71",
year="2011",
doi="10.1007/978-3-319-59888-8\_17"
}

@inproceedings{mccrae2011combining,
title={{Combining statistical and semantic approaches to the translation of ontologies and taxonomies}},
author="John McCrae and Mauricio Espinoza and Elena Montiel-Ponsoda and Guadalupe Aguado-de-Cea and Philipp Cimiano",
booktitle="Fifth Workshop on Syntax, Structure and Semantics in Statistical Translation in conjunction with 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies",
year="2011"
}

@inproceedings{mccrae2011linking,
title={{Linking Lexical Resources and Ontologies on the Semantic Web with lemon}},
author="John McCrae and Dennis Spohr and Philipp Cimiano",
booktitle="Proc. of the 8th Extended Semantic Web Conference",
pages="245-249",
year="2011",
doi="10.1007/978-3-319-59888-8\_17"
}

@inproceedings{buitelaar2011ontology,
title={{Ontology Lexicalization: The lemon perspective}},
author="Paul Buitelaar and Philipp Cimiano and John McCrae and Elena Montiel-Ponsoda and Thierry Declerck",
booktitle="Proc. of 9th International Conference on Terminology and Articial Intelligence",
year="2011"
}

@inproceedings{montiel2011representing,
title={{Representing Term Variation in lemon}},
author="Elena Montiel-Ponsoda and Guadalupe Aguado-de-Cea and John McCrae",
booktitle="Proc. of 9th International Conference on Terminology and Articial Intelligence",
year="2011"
}

@inproceedings{mccrae2010clova,
url="http://ceur-ws.org/Vol-571/571-complete.pdf\#page=10",
title={{CLOVA: An architecture for cross-language semantic data querying}},
author="John McCrae and Jesus R. Campa\~na and Philipp Cimiano",
booktitle="Proceedings of the 1st Workshop on the Multilingual Semantic Web",
pages="5-12",
year="2010"
}

@incollection{collier2010navigating,
url="https://www.crcpress.com/Biosurveillance-Methods-and-Case-Studies/KassHout-Zhang/9781439800461",
title={{Navigating the Information Storm: Web-based global health surveillance in BioCaster}},
author="Nigel Collier and Son Doan and Reiko Matsuda Goodwin and John McCrae and Mike Conway and Mika Shigematsu and Ai Kawazoe",
booktitle="Biosurveillance: Methods and Case Studies",
editor="Taha Kass-Hout and Xiaohui Zhang",
pages="291-312",
publisher="CRC Press",
year="2010",
doi="10.1007/978-3-319-59888-8\_17"
}

@incollection{declerck2010ontology,
title={{Ontology-based multilingual access to financial reports for sharing business knowledge across Europe}},
author="Thierry Declerck and Hans-Ulrich Krieger and Susan-Marie Thomas and Paul Buitelaar and Sean O'Riain and Tobias Wunner and Gilles Maguet and John McCrae and Dennis Spohr and Elena Montiel-Ponsoda",
booktitle="International Financial Control Assessment applying Multilingual Ontology Frameworks",
pages="67-76",
publisher="K\'esz\"ult a HVG Press Kft.",
year="2010"
}

@inproceedings{collier2010ontology,
title={{An ontology-driven system for detecting global health events}},
author="Nigel Collier and Reiko Matsuda Goodwin and John McCrae and Son Doan and Ai Kawazoe and Mike Conway and Asanee Kawtrakul and K. Takeuchi and D. Dien",
booktitle="In Proc. of the 23rd International Conference on Computational Linguistics",
pages="215-222",
year="2010"
}

@phdthesis{mccrae2009automatic,
title={{Automatic extraction of logically consistent ontologies from text corpora}},
author="John McCrae",
school="PhD Thesis for Graduate University of Advanced Studies (SoKenDai)",
year="2009"
}

@inproceedings{mccrae2009srl,
url="http://srl-editor.googlecode.com/files/saakm.pdf",
title={{SRL Editor: A rule development tool for text mining}},
author="John McCrae and Nigel Collier",
booktitle="Proc. of Workshop on Semantic Authoring, Annotation and Knowledge Markup in conjunction with the 5th International Conference on Knowledge Capture",
year="2009"
}

@article{mccrae2009synonym,
url="http://www.biomedcentral.com/1471-2105/9/159",
title={{Synonym set extraction from the biomedical literature by lexical pattern discovery}},
author="John McCrae and Nigel Collier",
journal="BMC Bioinformatics",
volume="9",
number="156",
year="2008",
doi="10.1007/978-3-319-59888-8\_17"
}

